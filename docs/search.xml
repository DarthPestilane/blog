<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx 反代 go module]]></title>
    <url>%2F2023%2F03%2F15%2FNginx-%E5%8F%8D%E4%BB%A3-go-module%2F</url>
    <content type="text"><![CDATA[在特定情况下，用 nginx 反代 git 仓库，且避免出现 go get meta tag did not match import path 的报错。配置如下:123456789101112131415161718192021222324location / &#123; if ($query_string ~ "go-get=1") &#123; set $condition goget; &#125; if ($uri ~ ^/([a-zA-Z0-9_\-\.]+)/([a-zA-Z0-9_\-\.]+).*$) &#123; set $condition "$&#123;condition&#125;path"; &#125; if ($condition = gogetpath) &#123; return 200 ' &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta name="go-import" content="$host/$1/$2 git http://$host/$1/$2.git"&gt; &lt;meta name="go-source" content="$host/$1/$2 _ http://$host/$1/$2/src/mster&#123;/dir&#125; http://$host/$1/$2/src/master&#123;/dir&#125;/file#L&#123;line&#125;"&gt; &lt;/head&gt; &lt;body&gt; $uri &lt;/body&gt; &lt;/html&gt; '; &#125; proxy_pass http://原本的git仓库;&#125;后续 go get 时，可能出现 terminal prompts disabled 的报错，使用 GIT_TERMINAL_PROMPT=1 go get 方可化解。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[disable mds_stores]]></title>
    <url>%2F2022%2F11%2F10%2Fdisable-mds-stores%2F</url>
    <content type="text"><![CDATA[记几个命令行，用来暂停/恢复 spotlight 搜索的索引进程:As you know, the mds and mds_stores are Spotlight activities.The reason why your Spotlight is so active could be a number of things; it could be you have an app or multiple apps constantly changing some folder contents.First let&#39;s check whether Spotlight is the cause of the fans running so much. To test this, run the following in your terminal:1sudo mdutil -a -i off # 暂停索引建立this turns off indexing of files, and should result in a clear slow down of the fans if mds and/or mds_stores are to blame.To turn indexing back on, run:1sudo mdutil -a -i on # 恢复索引建立After this you could run the complete re-indexing of your hard drive (be aware this could be an over night job), it will delete your Spotlight data base forcing it to start over.1sudo rm -rf /System/Volumes/Data/.Spotlight-V100/*The next and final step would be to add others to your (do not scan), privacy settings.参考自: https://apple.stackexchange.com/questions/144474/mds-and-mds-stores-constantly-consuming-cpumdutil 用法:12345678910111213141516171819202122$ mdutil --helpmdutil: unrecognized option `--help'Usage: mdutil -pEsa -i (on|off) -d volume ... mdutil -t &#123;volume-path | deviceid&#125; fileid Utility to manage Spotlight indexes. -i (on|off) Turn indexing on or off. -d Disable Spotlight activity for volume (re-enable using -i on). -E Erase and rebuild index. -s Print indexing status. -a Apply command to all stores on all volumes. -t Resolve files from file id with an optional volume path or device id. -p Publish metadata. -V vol Apply command to all stores on the specified volume. -v Display verbose information. -r plugins Ask the server to reimport files for UTIs claimed by the listed plugin. -L volume-path List the directory contents of the Spotlight index on the specified volume. -P volume-path Dump the VolumeConfig.plist for the specified volume. -X volume-path Remove the Spotlight index directory on the specified volume. Does not disable indexing. Spotlight will reevaluate volume when it is unmounted and remounted, the machine is rebooted, or an explicit index command such as 'mdutil -i' or 'mdutil -E' is run for the volume.NOTE: Run as owner for network homes, otherwise run as root.]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Homebrew 安装 disabled formula]]></title>
    <url>%2F2021%2F12%2F07%2FHomebrew-%E5%AE%89%E8%A3%85-disabled-formula%2F</url>
    <content type="text"><![CDATA[安装还在仓库里的 formula如果需要用 Homebrew 安装已经被 disable 掉的 formula，例如需要安装 v1.12 版本的 golang, 使用 brew install go@1.12 是无法安装的，需要修改对应的 formula 脚本:1&gt; brew edit go@1.12该操作会在默认的编辑器中打开位于 /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core/Formula 目录下的 go&#64;1.12.rb 脚本文件。编辑脚本文件，找到 disable 方法的调用，并注释掉，例如:1234567891011121314151617class GoAT112 &lt; Formula desc "Go programming environment (1.12)" homepage "https://golang.org" url "https://dl.google.com/go/go1.12.17.src.tar.gz" mirror "https://fossies.org/linux/misc/go1.12.17.src.tar.gz" sha256 "de878218c43aa3c3bad54c1c52d95e3b0e5d336e1285c647383e775541a28b25" license "BSD-3-Clause" # ...... keg_only :versioned_formula disable! date: "2021-02-16", because: :unsupported # **就是这一行** TODO: 注释掉 depends_on arch: :x86_64 # ......之后，再次使用 brew install go@1.12 ，虽然会有 warning 但最终还是可以顺利安装 v1.12 版本的 golang 。安装已给移除仓库的 formula通过 github 仓库搜索 go&#64;1.12.rb, 在 commits 中找到对应的提交。将 rb 文件保存到本地, 例如: go&#64;1.12.rb 。 然后执行:1&gt; HOMEBREW_NO_INSTALL_FROM_API=1 brew install ./go@1.12.rb]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[温故 base64 编码]]></title>
    <url>%2F2021%2F10%2F18%2F%E6%B8%A9%E6%95%85-base64-%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[温故 base64 编码过程。虽然现在绝大多数编程语言都已经在标准库中实现了 base64 编码和解码，但还是要时不时回顾其原理。编码原理TLDR: 将 8 位 二进制串 分割为 多个 4 个 6 位 二进制串，参考 https://zh.wikipedia.org/wiki/Base64 。将每个字符都转换成对应的 ASCII 码将每个 ASCII 码由十进制转为 8 位二进制将这些二进制按照每 6 位分进行分隔，4 个 6 位二进制位 一组 ，若在分隔的时候，位数不够则用 0 填补在末尾将这些 6 位的二进制重新转为十进制，并根据十进制数在 base64 索引表 中找到对应的编码。若构不成 一组，则用 = 号填补在末尾编码 (encode) 过程如下:TextASCII8 BitIndexBase64#tb td{padding:0;margin:0;text-align:center;min-width:1em}function buildTd(items, colspan = 0) { let tdString = ''; for (const item of items) { tdString += `${item}`; } return tdString; } // text const texts = ['m', 'i', 'x', 'x', ' ', ' ']; document.getElementById('tr-text').innerHTML += buildTd(texts, 8); // ascii const asciis = [109, 105, 120, 120, ' ', ' ']; document.getElementById('tr-ascii').innerHTML += buildTd(asciis, 8); // bits const bits = [ '0', '1', '1', '0', '1', '1', '0', '1', '0', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '0', '0', '0', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ] document.getElementById('tr-bits').innerHTML += buildTd(bits); // index const indices = [27, 22, 37, 56, 30, 0, ' ', ' ']; document.getElementById('tr-index').innerHTML += buildTd(indices, 6); // Base64 const base64s = ['b', 'W', 'l', '4', 'e', 'A', '=', '=']; document.getElementById('tr-base64').innerHTML += buildTd(base64s, 6);1echo -n 'mixx' | base64 # 输出: bWl4eA==程序简单实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * @var base64 索引表 索引从 0 到 63 * @see https://zh.wikipedia.org/wiki/Base64 */$base64Map = [ 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '/',];function base64Encode(string $data): string&#123; $binConcat = ''; $length = strlen($data); // 遍历字节 for ($i = 0; $i &lt; $length; $i++) &#123; $char = $data[$i]; $asciCode = ord($char); // 得到 ASCII 码 $bin = str_pad(decbin($asciCode), 8, '0', STR_PAD_LEFT); // 转为二进制并高位补0 $binConcat .= $bin; &#125; $sixBits = str_split($binConcat, 6); // 分割为6位数组 $sixBitsGroup = array_chunk($sixBits, 4); // 每4个为一组 $groupLen = count($sixBitsGroup); $lastGroup = $sixBitsGroup[$groupLen - 1]; $lastGroupLen = count($lastGroup); $lastGroup[$lastGroupLen - 1] = str_pad($lastGroup[$lastGroupLen - 1], 6, '0', STR_PAD_RIGHT); // 不足6位则用0填补末尾 $sixBitsGroup[$groupLen - 1] = $lastGroup; global $base64Map; // 引用 base64 索引表 // encode $base64Concat = ''; foreach ($sixBitsGroup as $sixBits) &#123; foreach ($sixBits as $sixBit) &#123; $dec = bindec($sixBit); // 二进制转十进制 $base64Concat .= $base64Map[$dec]; // 查询 base64 索引表，得到字符 &#125; &#125; // 用 '=' 补位 for ($i = 0; $i &lt; 4 - $lastGroupLen; $i++) &#123; $base64Concat .= '='; &#125; return $base64Concat;&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Jenkins 多分支 pipeline 配置]]></title>
    <url>%2F2021%2F10%2F09%2FJenkins-%E5%A4%9A%E5%88%86%E6%94%AF-pipeline-%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[最近恰巧有机会在一台 Centos 物理机上搭建 Jenkins， 也借此机会实践了从 git 提交自动触发 Jenkins build 的工作流，故在此记录，以作备忘。Jenkins 安装docker 镜像在 https://hub.docker.com/r/jenkins/jenkins 。docker-compose.yml 配置如下:123456789101112version: "3"services: jenkins: image: jenkins/jenkins:lts-alpine-jdk11 ports: - '8180:8080' # web 端口 - '50000:50000' volumes: - ./jenkins/:/var/jenkins_home # 持久化 environment: TZ: "Asia/Shanghai"需要注意宿主机的 ./jenkins/ 目录需要将用户和组更改为 1000:1000:1&gt; sudo chown -R 1000:1000 ./jenkins启动之后，进入 web 界面，需要输入 admin 的密码，这个密码可以在容器的日志中获得:1&gt; docker-compose logs jenkins # 查看容器日志1234567891011121314jenkins_1 | *************************************************************jenkins_1 | *************************************************************jenkins_1 | *************************************************************jenkins_1 |jenkins_1 | Jenkins initial setup is required. An admin user has been created and a password generated.jenkins_1 | Please use the following password to proceed to installation:jenkins_1 |jenkins_1 | aee0014b14124efe03c361e1eed93589jenkins_1 |jenkins_1 | This may also be found at: /var/jenkins_home/secrets/initialAdminPasswordjenkins_1 |jenkins_1 | *************************************************************jenkins_1 | *************************************************************jenkins_1 | *************************************************************接下来建议直接选择安装社区 推荐 的插件，然后进行简单配置后，就可以正常登陆到 Jenkins 控制台了， 然后进行slave节点配置，顺便配置下域名反代。Gitea 安装使用 Gitea 作为私有 git 代码仓库，docker 镜像在: https://hub.docker.com/r/gitea/gitea 。docker-compose.yml 配置如下:1234567891011121314version: "3"services: server: image: gitea/gitea:1.15.3 environment: - USER_UID=1000 - USER_GID=1000 volumes: - ./gitea:/data # 持久化 - /etc/timezone:/etc/timezone:ro - /etc/localtime:/etc/localtime:ro ports: - "3000:3000" # http 端口启动后，进入 web 界面进行安装，要注意 URL 里要填写容器内对应的地址。 如果配置了域名并进行反代，需要更改容器内的 app.ini 配置文件:1234567# 由于已经将文件挂载到了宿主机，所以直接修改宿主机文件即可。# ./gitea/gitea/conf/app.ini[server]DOMAIN = gitea.wrzsj.top # 修改成域名SSH_DOMAIN = gitea.wrzsj.top # 修改成域名ROOT_URL = https://gitea.wrzsj.top/ # 修改成域名，可以理解为外部 URLLOCAL_ROOT_URL = http://127.0.0.1:3000/ # 添加 LOCAL_ROOT_URL修改之后，重启容器 docker-compose restart server 。CI/CDJenkins 和 Gitea 都准备好后，接下来就要开始配置 CI/CD 了。工作流:git 分支操作:从 master 分支切出 dev 分支作为长期迭代分支从 dev 分支切出 feat 分支作为功能分支在 feat 分支上提交代码，并及时 rebase dev 来保证提交不落后，完成开发后通过 pull request 的方式合并回 dev 分支将 dev 分支合并回 master 分支在 master 分支上打 tag，用于发布对于线上的 bug 修复，应从 master 分支切出 hotfix 分支， 开发完成后合并到 dev 进行测试，测试通过后合并到 master ，然后打 tag 发布。CI/CD 触发:当 master 和 dev 分支发生 push 时，触发当 pull request 创建或有后续 push 时，触发每次触发都会执行 build, lint 和 test 任务如果由 dev 分支 push 触发，则部署到 QA 环境如果由 master 分支 push 触发，会进入打标签阶段，需要人工确认打上标签后，会进入部署到生产环境阶段，也需要人工确认配置Jenkins 配置安装 gitea 插件。新建 多分支流水线 任务。配置分支源:需要设置 Credentials ，使用类型为 Gitea Personal Access Token 的凭证添加 Discover branches，策略为 Only branches that are not also filed as PRs添加 Discover pull requests from origin，策略为 Merging the pull request with the current target branch revision添加 Discover tags添加 根据名称过滤（支持通配符), 包含 master dev release-* PR-*release-* 用来过滤 tag。在打 tag 的时候，需要有 release- 前缀PR-* 用来过滤 pull request添加高级克隆行为，勾选 Fetch tags 和 浅克隆，并设置 浅克隆深度 为 1保存配置。Gitea 配置在代码仓库里配置 webhook:添加 Gitea 钩子目标 URL 输入: https://jenkins.wrzsj.top/gitea-webhook/post/，注意要加上最后的斜杠 / ！！触发条件勾选 所有事件保存配置。Jenkinsfile 配置语法参考: https://www.jenkins.io/zh/doc/book/pipeline/syntax/ 。由于是 pipeline 类型的任务，需要通过 Jenkinsfile 来触发。在代码中提交 Jenkinsfile 文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869pipeline &#123; agent any options &#123; disableConcurrentBuilds() // 禁用并发构建 timestamps() // Console log 中打印时间戳 &#125; stages &#123; stage('Build') &#123; when &#123; not &#123; tag '*' &#125; &#125; steps &#123; echo 'build' sh 'sleep 1' &#125; &#125; stage('Lint') &#123; when &#123; not &#123; tag '*' &#125; &#125; steps &#123; echo 'lint' sh 'sleep 1' &#125; &#125; stage('Test') &#123; when &#123; not &#123; tag '*' &#125; &#125; steps &#123; echo 'test' sh 'sleep 1' &#125; &#125; stage('Deploy QA') &#123; when &#123; branch 'dev' &#125; steps &#123; echo 'deploy QA' &#125; &#125; stage('Tag on master') &#123; when &#123; branch 'master' beforeInput true &#125; input &#123; // 人工确认 message "Release a tag?" ok "Yes, do it." parameters &#123; string(name: 'milestone', defaultValue: 'regular', description: 'milestone as tag prefix') &#125; &#125; steps &#123; sh ''' export TAG=release-$&#123;milestone&#125;-$(date +"%Y%m%d").$&#123;BUILD_ID&#125; git tag $&#123;TAG&#125; git push origin $&#123;TAG&#125; ''' &#125; &#125; stage('Deploy Prod') &#123; when &#123; tag '*' beforeInput true &#125; input &#123; // 人工确认 message "Should we continue?" ok "Yes, do it." &#125; steps &#123; echo 'deploy production' &#125; &#125; &#125;&#125;现在，按照 Git 工作流来提交合并代码，就能够触发 Jenkins 流水线了。总结这次实践中，在 Jenkins 的使用上采取 master-slave 方式来运行流水线，相比只有 master 节点的工作方式，更加合理，且方便扩展。 配合 Jenkinsfile 的使用，实现了持续集成，搭建了敏捷开发的基础。不过对比 GitHub Actions 和 Gitlab CI 还是略显笨重和复古，配置文件的语法相比 yaml 也更加晦涩难懂，文档也略显粗糙。 尽管如此，大多数公司的 CI/CD 还是使用的是 Jenkins，所以是有必要学会的。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>CI</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用 Github Action 部署博客]]></title>
    <url>%2F2021%2F10%2F09%2F%E5%88%A9%E7%94%A8-Github-Action-%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[之前的博客是需要在我本地电脑上手动执行命令来部署的:1&gt; make deploy如今已经成功将这个部署的过程迁移到了 Github Actions。 整个 workflow 包括 npm 依赖的安装和缓存，将 Markdown 生成静态 html 文件，和部署到服务器。配置如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051name: deployon: push: branches: - 'master' # 只会在 master 分支发生 push 事件时，才触发jobs: deploy: runs-on: ubuntu-latest environment: # 环境变量在 github 项目的设置页面里进行配置 name: deploy # 这里需要手动进行授权，才会进行job steps: - name: Checkout Code uses: actions/checkout@v2 # 指定 nodejs 版本 - name: Setup Nodejs uses: actions/setup-node@v2 with: node-version: '12' # 依赖缓存设置 - name: Cache node dependency uses: actions/cache@v2 with: path: ~/.npm # 缓存目录 key: cache-node-$&#123;&#123; hashFiles('**/package-lock.json') &#125;&#125; # 缓存的key restore-keys: | # 恢复缓存时要去匹配的key cache-node- cache- # 安装 npm 依赖包 - name: Install dependency run: npm install # 生成静态文件 - name: Build to static run: make build # 部署到服务器，使用 rsync 来传递文件 - name: Deploy to server uses: burnett01/rsync-deployments@5.1 with: switches: -azvhP --delete path: ./public/ remote_path: $&#123;&#123; secrets.SSH_REMOTE_PATH &#125;&#125; # secrets 在 github 项目的设置页面里进行配置 remote_user: $&#123;&#123; secrets.SSH_USER &#125;&#125; remote_host: $&#123;&#123; secrets.SSH_HOST &#125;&#125; remote_port: $&#123;&#123; secrets.SSH_PORT &#125;&#125; remote_key: $&#123;&#123; secrets.SSH_SECRET &#125;&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>CI</tag>
        <tag>Github Actions</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 部署 JIRA]]></title>
    <url>%2F2021%2F09%2F24%2FDocker-%E9%83%A8%E7%BD%B2-JIRA%2F</url>
    <content type="text"><![CDATA[近日有机会在 Linux 环境中从零开始使用 docker 部署 JIRA, 在此记录下部署过程中遇到的问题及解决.镜像选择在 docker 的镜像仓库中搜索 &#39;jira&#39;, 会看到好几个相关的镜像: atlassian/jira-software, atlassian/jira-core 等. 这里应当选择 atlassian/jira-software.初次启动根据 dockerhub 中的描述, 编排出下面的 docker-compose.yml 配置:1234567891011version: '3'services: jira: image: atlassian/jira-software environment: TZ: Asia/Shanghai ports: - "18081:8080" volumes: - ./jira-data:/var/atlassian/application-data/jira # 应用数据持久化启动之后, 进入web界面, 选择手动配置, 然后开始配置 JIRA.在配置数据库时, 此时还只能选在内置数据库, 不能选择 MySQL 或者 PostgreSQL, 因为 atlassian/jira-software 镜像中并没有包含连接 MySQL 或 PostgreSQL 的驱动 jar 包. 接下来就需要去下载对应的 jar 包, 并将其放入容器中特定的目录下, 来完成 MySQL 或 PostgreSQL 的配置.载入驱动, 配置 PostgreSQL 数据库更新 docker-compose.yml 来添加 PostgreSQL 容器, 并与 jira-software 关联上:1234567891011121314151617181920212223242526272829303132333435version: '3'services: jira: image: atlassian/jira-software environment: TZ: Asia/Shanghai depends_on: - postgres # 关联上 postgres ports: - "18081:8080" volumes: - ./jira-data:/var/atlassian/application-data/jira # 应用数据持久化 # 添加 postgres 容器 postgres: image: postgres:11-alpine ports: - "15432:5432" environment: TZ: Asia/Shanghai POSTGRES_DB: jira POSTGRES_USER: postgres POSTGRES_PASSWORD: postgres POSTGRES_HOST_AUTH_METHOD: trust volumes: - ./pgdata:/var/lib/postgresql/data # 数据库持久化# 如果是 Mac 环境, 最好是使用单独的 volume 来做数据持久化## volumes:# jiradata:# external: false# pgdata:# external: false至此, 还需要载入 PostgreSQL 驱动, 才能完成数据库的配置.访问 startup-check-jira-database-driver-missing 可得知对应数据库驱动的下载地址. 下载得到的 jar 包为 postgresql-42.2.23.jar, 现在需要将其放入 jira-software 容器中的 /opt/atlassian/jira/lib 目录下, 使用 docker cp 命令即可完成.重启容器后, PostgreSQL 驱动已完成载入, 可以在 web 界面完成数据库配置了.激(po)活(jie) JIRA当进行到激活步骤时, 需要提供 license-key 才可激活 JIRA, 然而我并没有购买 license-key, 所以需要一些特殊手段来激活.由于 jira-software 的版本是 8.x, 需要 atlassian-agent 来提供 license-key 用来激活. 下载并解压后得到 atlassian-agent.jar, 还是需要将其放入 jira-software 容器中的 /var/local/agent 目录下(目录可以自己定), 记住这个目录，后面会用到. 然后进入容器内的 opt/atlassian/jira/bin 目录, 修改 setenv.sh 文件:123456# 找到 export JAVA_OPTSexport JAVA_OPTS# 仅添加下面这一行. /var/local/agent 为 atlassian-agent.jar 所在目录export JAVA_OPTS="-javaagent:/var/local/agent/atlassian-agent.jar $&#123;JAVA_OPTS&#125;"重启容器, 可能需要重新配置刚才已经配置过的条目, 直到来到激活步骤. 进入 jira-software 容器的 /var/local/agent 目录, 也就是 atlassian-agent.jar 所在目录, 执行:123$ java -jar atlassian-agent.jar -p jira -m aaa@local.com -n my_name -o https://local.com -s '这里填写 web 页面上的 server id, 或者留空'# java -jar atlassian-agent.jar -h 可以打印出帮助信息将 license-key 填入, 方可完成激活.===接下来完成剩下的一些配置, JIRA 就按照完毕了.]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git commit message standard]]></title>
    <url>%2F2021%2F09%2F22%2Fgit-commit-message-standard%2F</url>
    <content type="text"><![CDATA[回首这些年工作和业余时间的 git 使用，发现在提交内容时，写的 commit message 其实并没有做到统一和规范化。 于是抽空去 Google 了一番，发现有不少的开源项目在使用一种语义化的提交。 这种语义化的提交能够做到足够简短且开门见山。 看过之后确实也是受益匪浅，故在此记录。https://gist.github.com/joshbuchea/6f47e86d2510bce28f8e7f42ae84c716 。 这是一个拥有 2k+ star 的 gist，里面陈述着语义化提交的基本范式。 下面是我个人对这套规范的理解。语义化的提交来看看这个提交信息的小小改动，能对你的程序带来多少益处吧。格式: &lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;，其中 &lt;scope&gt; 是非必要的。123456git commit -m "feat: add hat wobble" ^--^ ^------------^ | | | +-&gt; 总结内容(subject)，注意是用现在时态 | +-------&gt; 类型(type): chore, docs, feat, fix, refactor, style, test不同类型(type)的语义Type语义feat针对用户侧的新特性。是对外的而非对内的fix针对用户侧的 bug 修复。是对外的而非对内的docs仅文档内容的变更style仅格式化相关，比如行尾的分号(;)，空格等。不影响线上使用refactor重构功能代码，如重命名变量，抽象方法等test添加或重构单元测试。不影响线上使用chore更新 CI/CD 流程、任务或脚本。不影响线上使用]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go Blog 翻译: Fuzzing is Beta Ready]]></title>
    <url>%2F2021%2F09%2F15%2FGo-Blog-%E7%BF%BB%E8%AF%91-Fuzzing-is-Beta-Ready%2F</url>
    <content type="text"><![CDATA[Fuzzing is Beta Ready原文地址 : https://blog.golang.org/fuzz-beta作者 : Katie Hockman and Jay Conrod时间 : 3 June 2021我们兴奋地宣布: 原生 fuzzing 已经可供beta测试了，就在 dev.fuzz 中的 development 分支里！Fuzzing 是自动化测试的一种，通过持续操控程序的输入来找出问题，比如说 panic 或 bug。 这些半随机的变换数据能够覆盖到已有单元测试所遗漏的地方，并且揭露出一些不易察觉的边界 bug。 正因为 fuzzing 可以抵达这些边界情况，fuzz 测试对于查找安全漏洞和弱点是尤为重要的。详见 golang.org/s/draft-fuzzing-design 。Getting started你可通过运行下面命令来上手12$ go get golang.org/dl/gotip$ gotip download dev.fuzz该操作从 dev.fuzz 的 development 分支构建 Go toolchain，将来一旦代码合并到了 master 分支就不用这样了。 运行之后，gotip 可以看做 go 命令的绿色替代 (drop-in replacement)。 你现在可以这样运行命令1$ gotip test -fuzz=FuzzFoo因为在 dev.fuzz 分支中会不断地开发和bug修复，所以你应当有规律地执行 gotip download dev.fuzz 来应用最新的代码。为兼容已发行的 Go 版本，在提交含有 fuzz target 的源文件到仓库时，要使用 gofuzzbeta build tag。 dev.fuzz 分支中，这个 tag 在 build-time 是默认开启的。 如果你对 tags 使用有疑问，参考 the go command documentation about build tags。1// +build gofuzzbetaWriting a fuzz targetfuzz target 必须是 *_test.go 文件中以 FuzzXxx 形式命名的 function。 该 function 必须传递一个 *testing.F 参数，很类似于传递一个 *testing.T 参数到 TestXxx function。下面是个 fuzz target 的例子，用来测试 net/url 包 的行为。123456789101112131415161718192021222324252627// +build gofuzzbetapackage fuzzimport ( "net/url" "reflect" "testing")func FuzzParseQuery(f *testing.F) &#123; f.Add("x=1&amp;y=2") f.Fuzz(func(t *testing.T, queryStr string) &#123; query, err := url.ParseQuery(queryStr) if err != nil &#123; t.Skip() &#125; queryStr2 := query.Encode() query2, err := url.ParseQuery(queryStr2) if err != nil &#123; t.Fatalf("ParseQuery failed to decode a valid encoded query %s: %v", queryStr2, err) &#125; if !reflect.DeepEqual(query, query2) &#123; t.Errorf("ParseQuery gave different query after being encoded\nbefore: %v\nafter: %v", query, query2) &#125; &#125;)&#125;你可以用 go doc 阅读更多 fuzzing 的 API1234gotip doc testinggotip doc testing.Fgotip doc testing.F.Addgotip doc testing.F.FuzzExpectations由于这是 development 分支的 beta 发布，所以很可能遭遇 bug 和不完善的 feature。查看 &quot;fuzz&quot; 相关的 issue tracker 来跟进已有的 bug 和 遗漏的 feature。请注意，fuzzing 很可能会消耗大量内存，在运行过程中也许会影响你机器的性能。go test -fuzz 默认是根据 $GOMAXPROCS 来并行运行。 你可以设置 go test 的 -parallel flag 来降低并行数量。如果想获得更多信息，可执行 gotip help testflag go 命令来阅读 go test 命令文档。也要注意，在运行中，fuzzing 引擎会写入那些扩大测试覆盖的值到 fuzz 缓存目录，位于 $GOCACHE/fuzz。 由于目前还没有文件数量或写入数据大小的限制，所以这可能会占据大量的存储空间 (好几个GB)。你可以通过运行 gotip clean -fuzzcache 来清理 fuzz 缓存。What’s next?这个 feature 是不会出现在即将到来的 Go 版本中 (go1.17)，但计划会出现在未来的 Go 版本中。 我们希望这个还在开发中的原型 feature 会让 Go 开发者开始编写 fuzz target 并提供关于设计上有帮助的反馈，为合并到 master 做准备。如遇任何问题或对 feature 有想法，请 提 issue。你可参与 Gophers Slack 的 #fuzzing channel，来对 feature 进行讨论或反馈。Happy fuzzing!]]></content>
      <categories>
        <category>笔记</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go Blog 翻译: Context and Structs]]></title>
    <url>%2F2021%2F04%2F21%2FGo-Blog-%E7%BF%BB%E8%AF%91-Context-and-Structs%2F</url>
    <content type="text"><![CDATA[Context and Structs原文地址: https://blog.golang.org/context-and-structs作者: Jean de Klerk, Matt T. Proud时间: 24 February 2021Introduction在许多尤其是现代的 Go API 中, function 或 method 的第一个参数常常是 context.Context. Context 为传输提供了 deadline, 为调用方提供了 cancellation, 也为其他进程间跨 API 请求提供了传值手段. 它常常被间接或直接使用了远程服务的库所使用, 例如数据库, API 等.Context 文档 所述:Context 不应存储在 struct 内部, 而应传给需要它的 function.这篇文章就是针对上述建议的详述, 通过举例说明的方式来阐述为什么要传递 Context 而不是存储在另一个 type 里. 本文也强调了一种边缘情况: 将 Context 存储在 struct 中也是合理的. 以及如何安全实现.Prefer contexts passed as arguments要理解这个建议: 不要把 Context 存储在 struct 中. 我们先看看建议的方式下写的代码:123456789101112131415type Worker struct &#123; /* … */ &#125;type Work struct &#123; /* … */ &#125;func New() *Worker &#123; return &amp;Worker&#123;&#125;&#125;func (w *Worker) Fetch(ctx context.Context) (*Work, error) &#123; _ = ctx // A per-call ctx is used for cancellation, deadlines, and metadata.&#125;func (w *Worker) Process(ctx context.Context, work *Work) error &#123; _ = ctx // A per-call ctx is used for cancellation, deadlines, and metadata.&#125;(*Worker).Fetch 和 (*Worker).Process 两个方法都直接接受 context 参数. 在 pass-as-argument 的设计下, 用户可以对每次调用设置 deadlines, cancellation, 和 metadata. 而且, context.Context 传到每个方法的方式是很清晰的, 不用去担心 context.Context 会不会在其他方法中用到. 这是因为 context 被划定为了操作所需的最小粒度, 这极大地增强了包中 context 的实用性和清晰度.Storing context in structs leads to confusion我们再来用 不推荐 的 context-in-struct 方式来审视下代码. 这问题在于, 当你把 context 存储在 struct 里, 调用方就无法看清楚 context 的生命周期, 情况得不可预测:123456789101112131415type Worker struct &#123; ctx context.Context&#125;func New(ctx context.Context) *Worker &#123; return &amp;Worker&#123;ctx: ctx&#125;&#125;func (w *Worker) Fetch() (*Work, error) &#123; _ = w.ctx // A shared w.ctx is used for cancellation, deadlines, and metadata.&#125;func (w *Worker) Process(work *Work) error &#123; _ = w.ctx // A shared w.ctx is used for cancellation, deadlines, and metadata.&#125;(*Worker).Fetch 和 (*Worker).Process 方法都使用了存储在 Worker 里的 context. 这阻碍了 Fetch 和 Process 调用方 (可能他们拥有各自不同的 context) 在每次调用时的基本操作: 指定 deadline, 请求 cancellation 以及附加 metadata. 例如: 用户无法仅为 (*Worker).Fetch 提供 deadline, 也无法仅为 (*Worker).Process 提供 cancel. 因为context是共享的, 所以调用方的生命周期是虚实夹杂的, 并且当 Worker 被创建时, context 就会被作用于整个生命周期.相比 pass-as-argument 方式, 用户会对这个 API 感到很疑惑, 心想:New 方法会被传入 context.Context, 那这个构造方法在执行时会需要 cancelation 或 deadlines 吗?在 New 方法中传入的 context.Context 会被 (*Worker).Fetch 和 (*Worker).Process 方法使用吗? 两个方法都不会用到? 还是说有方法会用到?这个 API 也需要有大量的文档来明确地告诉用户, context.Context 具体是用来干什么的. 用户也不得不读源码而不能依赖 API 所传达的结构.而且, 这可能是很危险的, 将这样的设计方式运用在生产级别的服务器上. 因为如果不是每个请求都有一个 context, 就不能充分地&quot;尊重&quot; cancellation. 不能对每次调用设置 deadline, 你的进程可能会堆积和耗尽其资源 (比如 内存)!Exception to the rule: preserving backwards compatibility当 Go 1.7 带着 context.Context 发布后, 大量的 API 需要以向后兼容的方式添加 context 支持. 例如: net/http 中 Client 方法, 像 Get 和 Do, 就是 context 极佳的候选者. 通过这些方法所发出的外部请求都会受益于由 context.Context 带来的 deadline, cancellation, 和 metadata 的支持.有两种方式来添加向后兼容的 context.Context 支持: 一种是将 context 定义在 struct 里 (context-in-struct), 另一种, 正如我们所见, 是复制函数来接收 context.Context 参数, 并将 Context 作为新函数的名后缀. 复制函数的方式相比 context-in-struct 更好, 更深入的讨论详见 Keeping your modules compatible. 然而, 在某些情况下这是不现实的: 比如你的 API 暴露了大量的方法, 将他们全都复制一遍也许是不可行的.net/http 包选择 context-in-struct 的方式, 它为我们提供了一个有用的案例来学习. 我们来看看 net/http 的 Do 方法. 在引入 context.Context 之前, Do 方法是这样定义的:1func (c *Client) Do(req *Request) (*Response, error)在 Go 1.7 之后, 如果不是为了保证向后兼容, Do 方法可能会是这样:1func (c *Client) Do(ctx context.Context, req *Request) (*Response, error)但是! 确保向后兼容及秉持 Go 1 promise of compatibility, 对于标准库来说, 是至关重要的. 因此, 维护人员选择了将 context.Context 添加到 http.Request struct 中, 来实现 context.Context 的支持, 而不破坏兼容性:123456789101112131415type Request struct &#123; ctx context.Context // ...&#125;func NewRequestWithContext(ctx context.Context, method, url string, body io.Reader) (*Request, error) &#123; // Simplified for brevity of this article. return &amp;Request&#123; ctx: ctx, // ... &#125;&#125;func (c *Client) Do(req *Request) (*Response, error)由此看来, 在改造 API 支持 context 时, 将 context.Context 添加到 struct 里也可以是合理的. 然而, 要记住首选仍然是复制方法, 它既可以保证 context.Context 的兼容性, 也不会牺牲通用性和可读性. 例如:1234567func (c *Client) Call() error &#123; return c.CallContext(context.Background())&#125;func (c *Client) CallContext(ctx context.Context) error &#123; // ...&#125;ConclusionContext 让跨库 / 垮 API 传播重要信息到调用栈变得容易.但也须要做到贯彻到底和条理清晰, 来保证可读性, 方便debug, 和有效性.当 Context 用作第一个参数, 而不是存储在 struct 时, 用户可以利用其扩展性构建强大的 cancelation, deadline, 和 metadata 调用栈. 同时, 最棒的是, 当 Context 用作第一个参数传递时, 其作用域是能被充分理解的, 这让整个调用栈都具有可读性和易调试性的.当在设计一个包含 context 的 API 时, 记住这个建议:pass context.Context in as an argument; don&#39;t store it in structs.]]></content>
      <categories>
        <category>笔记</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[REGRETS OF THE DYING]]></title>
    <url>%2F2021%2F01%2F11%2FREGRETS-OF-THE-DYING%2F</url>
    <content type="text"><![CDATA[For many years I worked in palliative care. My patients were those who had gone home to die. Some incredibly special times were shared. I was with them for the last three to twelve weeks of their lives.我从事保守治疗许多年，我的病人都是回到家中逝世的。 我们共度了一些非常特殊的时光，我陪在他们身边，在他们生命最后的3到12周。People grow a lot when they are faced with their own mortality. I learnt never to underestimate someone’s capacity for growth. Some changes were phenomenal. Each experienced a variety of emotions, as expected, denial, fear, anger, remorse, more denial and eventually acceptance. Every single patient found their peace before they departed though, every one of them.人们在面临固有一死的命运时会有许多觉悟，永远不要低估某人的觉悟能力，这是我领略到的。 有些人的改变是非凡的，他们每个人都体会到了各种各样的情感: 期许，否认，恐惧，愤怒，后悔，跟多的否认，以及最终的接受和释怀。 每位病人在离开之前都找到了自己内心的安详。When questioned about any regrets they had or anything they would do differently, common themes surfaced again and again. Here are the most common five:当问到他们有没有什么后悔的事情时，总会谈及些普遍的话题。下面是5个最常见的：I wish I’d had the courage to live a life true to myself, not the life others expected of me.我希望我曾拥有勇气去忠于自己地生活，而不是按照别人期望的方式。This was the most common regret of all. When people realise that their life is almost over and look back clearly on it, it is easy to see how many dreams have gone unfulfilled. Most people had not honoured even a half of their dreams and had to die knowing that it was due to choices they had made, or not made.这是最常提及的一种后悔。当人们意识到自己的生命即将结束时，回顾此生，很容易就看到许多梦想已变得无法实现。 大多数人都没有对梦想的荣誉进行捍卫，然后就得死去，他们心知肚明这是由于自己的选择造成的。It is very important to try and honour at least some of your dreams along the way. From the moment that you lose your health, it is too late. Health brings a freedom very few realise, until they no longer have it.在人生路上，尝试去捍卫哪怕一丁点自己梦想的荣誉是很重要的。 从你失去健康的那一刻起，就已经太迟了。健康带来的是自由，很少人能意识到这点，直到失去健康。I wish I hadn’t worked so hard.我希望我不曾那么拼命地工作This came from every male patient that I nursed. They missed their children’s youth and their partner’s companionship. Women also spoke of this regret. But as most were from an older generation, many of the female patients had not been breadwinners. All of the men I nursed deeply regretted spending so much of their lives on the treadmill of a work existence.每一位我照顾过的男性患者都会这么说。他们错过了子女的年少时期，错过了另一半的陪伴时光。 女性患者也谈到过这样的后悔，但大多数是老一辈的人，多数女性患者都不用养家糊口。 我所照顾过的所有男性患者都深深地感到后悔，后悔花费了大部分的人生在工作上。By simplifying your lifestyle and making conscious choices along the way, it is possible to not need the income that you think you do. And by creating more space in your life, you become happier and more open to new opportunities, ones more suited to your new lifestyle.通过简化生活方式和做出明白的抉择，可能就会发现你并不需要你当时认为需要的收入。 同时，给生活腾出更多的空间，你会感到更加幸福，也更能拥抱新的、更适合你新的生活方式的机遇。I wish I’d had the courage to express my feelings.我希望我曾拥有勇气来表达我的感受Many people suppressed their feelings in order to keep peace with others. As a result, they settled for a mediocre existence and never became who they were truly capable of becoming. Many developed illnesses relating to the bitterness and resentment they carried as a result.许多人都压抑着自己的感受来和他人和睦相处，结果就是他们过着平庸的生活，无法发挥出自己的全部去才能，许多人还会在痛苦和埋怨中生病。We cannot control the reactions of others. However, although people may initially react when you change the way you are by speaking honestly, in the end it raises the relationship to a whole new and healthier level. Either that or it releases the unhealthy relationship from your life. Either way, you win.我们不能控制别人做出的反应，然而当你开始实话实说后，人们虽然会有对此做出不适的反应，但到最后会建立起一个全新的更健康的人际关系， 如果不是这样，则这个不健康的人际关系就会被剔除。 怎么样你都是赢。I wish I had stayed in touch with my friends.我希望我能和朋友们保持联系Often they would not truly realise the full benefits of old friends until their dying weeks and it was not always possible to track them down. Many had become so caught up in their own lives that they had let golden friendships slip by over the years. There were many deep regrets about not giving friendships the time and effort that they deserved. Everyone misses their friends when they are dying.他们通常不会真正意识到老朋友的益处，直到等到他们快要面临死的那几周；而且也不一定能联络上这些朋友。 许多人都的生活节奏都太快了，以至于让金贵的友谊一年年渐渐溜走。有很多深深的遗憾都是关于友谊的，他们没有为友谊的维持贡献出足够的时间和努力。 所有人都在临终前想念他们的朋友。It is common for anyone in a busy lifestyle to let friendships slip. But when you are faced with your approaching death, the physical details of life fall away. People do want to get their financial affairs in order if possible. But it is not money or status that holds the true importance for them. They want to get things in order more for the benefit of those they love. Usually though, they are too ill and weary to ever manage this task. It all comes down to love and relationships in the end. That is all that remains in the final weeks, love and relationships.在忙碌的生活方式中，友谊的流逝是很普遍的。但当你不得不面对自己的死亡时，那些生活中物质的一面会渐渐消模糊。 人们确实希望尽可能地去创造财富，但真正重要的并不是钱或者地位。 他们为了自己的所爱而努力去带来更多的物质，但通常他们都太体弱多病而无法达成这个目标。 所有这一切都归结到爱和关系，这就是在最终的几周时间内剩下的全部内容了。I wish that I had let myself be happier.我希望我曾可以让自己过得更开心一些This is a surprisingly common one. Many did not realise until the end that happiness is a choice. They had stayed stuck in old patterns and habits. The so-called ‘comfort’ of familiarity overflowed into their emotions, as well as their physical lives. Fear of change had them pretending to others, and to their selves, that they were content. When deep within, they longed to laugh properly and have silliness in their life again.令人惊讶的是，许多患者到最后才意识到开心是一种选择。 他们禁锢在陈旧的方式和习惯中，所谓的舒适感从他们的情感中和物质生活中溢出。 因为害怕改变，他们变得自欺欺人，安于现状。在内心深处，他们渴望在生命中再次适当地欢笑和犯糊涂。When you are on your deathbed, what others think of you is a long way from your mind. How wonderful to be able to let go and smile again, long before you are dying.当你时日已尽，别人怎么看你已经无关紧要了，在死之前能够释怀和再次微笑是多么的美妙啊。Life is a choice. It is YOUR life. Choose consciously, choose wisely, choose honestly. Choose happiness.生活是一种选择。这是 你的 生活，请清醒地、明智地、诚实地选择。请选择幸福。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[理解 Golang 中的 nil 判断]]></title>
    <url>%2F2020%2F08%2F17%2F%E7%90%86%E8%A7%A3-Golang-%E4%B8%AD%E7%9A%84-nil-%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[nil 的含义从单词的角度来看， nil 有多个意思，但通常都表示 零，在 Golang 中，有些类型的零值是 nil 而有的不是。12345678910// 不同类型的零值var n int // 0var s string // ""var b bool // falsevar p *Pointer // nilvar slice []byte // nilvar m map[string]string // nilvar fn func() error // nilvar ch chan int // nilvar i interface&#123;&#125; // nilPointer 的零值一个 pointer (指针) 变量，表示该变量指向了某一个内存地址，当我们只是声明了一个指针变量，而不指明其指向的内存地址， 这个变量就会是 nil:123type Person struct &#123;&#125;var ptr *Person // 声明了一个指针变量，但是没有说明指针地址assertTrue(ptr == nil)Slice 的零值slice 是数组的切片，其内部有三个元素构成:123456// 伪代码type slice struct &#123; Ptr *pointer // 指向底层数组的指针 Len int // 长度 Cap int // 容量&#125;当我们只是声明了一个 slice 后，并没有告诉 slice 要指向那个底层数组，所以此时 Ptr 为 nil:12345var s []byte // s 中的 Ptr 为 nilassertTrue(s == nil) // 此时，变量 s == nil 为 truevar ss = []int&#123;1, 2, 3&#125; // ss 是知道自己的底层数组的assertTrue(ss != nil) // 所以不为 nilMap, Channel, Function 的零值这三种类型的零值为 nil ，是因为当我们声明了变量后，并没有说明该变量对应的 implemention (实现) 是什么。Interface 的零值首先思考一个例子，实际开发中不要这样做:123456789101112131415161718type MyError struct&#123;&#125; // MyError 实现 error 接口func (*MyError) Error() string &#123; return "here is my error"&#125;func NewError() error &#123; var myErr *MyError return myErr // 返回时把 myErr 转为 error 接口&#125;func main() &#123; err := NewError() if err == nil &#123; // cool! &#125; else &#123; // whoops.. &#125;&#125;我们调用 NewError() 后得到的 err 是 nil 吗？运行后发现 err 不为 nil。要解释这个现象需要从 interface 的结构说起。interface 内部有两个元素 ———— type (类型) 和 value (值):12345// 伪代码type interface struct &#123; Type xx // 类型 Value xx // 值&#125;在上述 NewError() 方法的定义里，我们声明了一个空指针变量 myErr ，这个变量为 nil ， 然后返回的时候将 myErr 转成了 error 接口。调用后得到的 err 变量已经是一个 interface 了， 而此时这个 interface 的值为 nil ，但类型是 *MyError ，所以 err == nil 会是 false。再回过头来看看:123456var i interface&#123;&#125; // value 和 type 都为空assertTrue(i == nil) // 所以整个 interface == nilvar p *Pointer // p == nilvar t interface&#123;&#125; = p // t 的值为nil，但类型为 *PointerassertTrue(t != nil) // 所以 t != nil]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Macbook usb断连问题]]></title>
    <url>%2F2019%2F09%2F16%2F%E8%A7%A3%E5%86%B3Macbook-usb%E6%96%AD%E8%BF%9E%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[有一天想用macbook的usb接口给苹果手机充电，连上之后出现连接不稳定，充电断断续续的情况。 换了另一台手机和另一根数据线，也出现这样的情况，当时以为是电脑出问题了。 后来在网上找到了解决方法。执行下面两个命令，可以让usbd服务重启，从而解决连接不稳定的问题。1sudo killall -STOP -c usbd # will pause the issue related process1sudo killall -CONT usbd # will resume the process]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP 垃圾回收机制]]></title>
    <url>%2F2019%2F07%2F11%2FPHP-GC%2F</url>
    <content type="text"><![CDATA[引用计数器的基本概念PHP 变量是存放于一个叫做 &quot;zval&quot; 的容器中。zval 容器包含了变量的类型和值以及附加的两位 (bit) 信息。第一个叫做 &quot;is_ref&quot; 是个 bool 值，表示变量是否为 &quot;reference set&quot; 的一部分。通过这个位信息，PHP 引擎即可区分该变量是普通变量还是引用。由于 PHP 允许用户 (user-land) 通过 &amp; 操作符来创建引用，zval 容器也包含了一个内部的引用计数机制用来优化内存使用。第二个位信息叫做 &quot;refcount&quot;，它包含指向这个 zval 容器的变量名称 (也叫符号 (symbols) ) 个数。所有的符号都存放在符号表 (symbol table) 中，其中，每个符号都有自己的作用域 (scope)。对于主脚本 (例: 被浏览器请求的脚本) 和每个函数或方法也都有作用域。当一个变量被赋常量值时，就会生成一个 zval 变量容器，像这样:1$a = "new string";这个例子中，一个新的符号名 a 在当前作用域被创建了，也有一个新的变量容器被创建了，其类型是 string，值是 &quot;new string&quot;。&quot;is_ref&quot; 位默认是 FALSE，因为还没有引用被用户创建。&quot;refcount&quot; 为 1 因为只有一个符号在使用这个变量容器。注意，如果 &quot;refcount&quot; 为 1，&quot;is_ref&quot; 只会为 FALSE。如果你安装了 Xdebug，亦可以调用 xdebug_debug_zval() 方法来展示信息。12$a = "new string";xdebug_debug_zval('a');上面的例子将输出:1a: (refcount=1, is_ref=0)='new string'将这个变量赋值给另一个变量会增加 &quot;refcount&quot;。123$a = "new string";$b = $a;xdebug_debug_zval( 'a' );上面的例子将输出:1a: (refcount=2, is_ref=0)='new string'现在 &quot;refcount&quot; 是 2，因为同一个变量容器被关联 (linked) 到了 a 和 b。PHP 足够聪明，在非必要时不会去拷贝实际的变量容器。容器变量在 &quot;refcount&quot; 减至 0 时被销毁。当有关联的变量容器的符号离开了作用域 (如: 函数结束时) 或者被取消赋值 (如: 被 unset() 时) 时，&quot;refcount&quot; 会减 1。下面的例子就能说明:1234567$a = "new string";$c = $b = $a;xdebug_debug_zval( 'a' );$b = 42;xdebug_debug_zval( 'a' );unset( $c );xdebug_debug_zval( 'a' );上面的例子将输出:123a: (refcount=3, is_ref=0)='new string'a: (refcount=2, is_ref=0)='new string' // when $b assigned by a new valuea: (refcount=1, is_ref=0)='new string' // when $c is unset()如果我们现在调用 unset($a);，容器变量(包括类型和值)将从内存中被移除。复合类型对于复合类型而言，比如数组和对象，事情会变得稍微复杂些。和标量 (scalar) 值相反，数组和对象将自己的成员存放在自己的符号表中。这意味着下面的示例创建了 3 个 zval 容器:12$a = ['meaning' =&gt; 'life','number' =&gt; 42];xdebug_debug_zval( 'a' );上面的例子将输出类似这样的东西:1234a: (refcount=1, is_ref=0)=array ( 'meaning' =&gt; (refcount=1, is_ref=0)='life', 'number' =&gt; (refcount=1, is_ref=0)=42)或者是这样的图示:3 个 zval 容器分别是: a，meaning 和 number。相似的规则同样可用来减少 &quot;refcounts&quot;。下面，我们添加另一个元素到数组中，并将值设置为一个已存在元素的内容:123$a = ['meaning' =&gt; 'life','number' =&gt; 42];$a['life'] = $a['meaning'];xdebug_debug_zval( 'a' );上面的例子将输出类似这样的东西:12345a: (refcount=1, is_ref=0)=array ( 'meaning' =&gt; (refcount=2, is_ref=0)='life', 'number' =&gt; (refcount=1, is_ref=0)=42, 'life' =&gt; (refcount=2, is_ref=0)='life')或者是这样的图示:从上述 Xdebug 输出中，我们可以看出新老数组元素现在指向了一个 &quot;refcount&quot; 为 2 的zval 容器。虽然 Xdebug 的输出中有两个值为 &quot;life&quot; 的 zval 容器，但是他们其实同一个。虽然 xdebug_debug_zval() 函数不会说明这个，但你可以通过查看内存指针来分辨。从数组中移除元素就像是将符号从作用域中移除一样。移除后，数组元素所指向的容器的 &quot;refcount&quot; 会被减少。同样，当 &quot;refcount&quot; 减至 0 时，变量容器将会从内存中移除。下面的例子可以说明:1234$a = ['meaning' =&gt; 'life', 'number' =&gt; 42];$a['life'] = $a['meaning'];unset( $a['meaning'], $a['number'] );xdebug_debug_zval( 'a' );上面的例子将输出类似这样的东西:123a: (refcount=1, is_ref=0)=array ( 'life' =&gt; (refcount=1, is_ref=0)='life')现在，如果我们将数组本身作为一个元素添加到数组中，事情就变得有趣了，我们将在下面的例子中这么做，而且会悄悄地添加一个引用操作符，不然 PHP 会创建一个拷贝:123$a = ['one'];$a[] = &amp;$a;xdebug_debug_zval( 'a' );上面的例子将输出类似这样的东西:1234a: (refcount=2, is_ref=1)=array ( 0 =&gt; (refcount=1, is_ref=0)='one', 1 =&gt; (refcount=2, is_ref=1)=...)或者是这样的图示:可以看出数组变量 (a) 和 第二个元素 (1) 现在都指向了一个 &quot;refcount&quot; 为 2 的变量容器。上面的 &quot;...&quot; 表示发送了递归，当然，在这里意味着指回了起源数组。和之前一样，对一个变量进行 unset() 会移除其符号，其指向的变量容器的引用数 (reference count) 将被减 1。所以如果我们在上述代码后面 unset 变量 $a，那么 $a 和 元素 (1) 所指向的变量容器的引用数就会减 1，由 &quot;2&quot; 变为 &quot;1&quot;。可以这样呈现:1234(refcount=1, is_ref=1)=array ( 0 =&gt; (refcount=1, is_ref=0)='one', 1 =&gt; (refcount=1, is_ref=1)=...)或者是这样的图示:清理问题虽然在任何作用域中都没有符号指向这个结构了，但是它无法被清理掉，因为数组元素 &quot;1&quot; 仍然指向自己本身。由于没有额外的符号指向它，所以对于用户来讲，是无法清理掉这个结构的，于是你就遇上了内存泄露。幸运的是，PHP 会在请求结束时清理掉这个数据结构，但在这之前，将会占去宝贵的内存空间。如果你在实现解析算法或者其他东西时将子元素指回了父元素，这种情况就会经常发生。当然，同样的情况也会发生在对象身上，而且可能性更高，因为对象总是隐式地被引用。这样的情况发生一两次倒也不是问题，但如果发生上千次或者几十万次的内存流失，这明显就成问题了。这样的问题往往发生在长时间运行的脚本中，比如守护进程 (请求基本上永远不会结束) 或者大量的单元测试。后者，在对 eZ Components 库的 Template 组建做单元测试时，有时会需要使用超过 2GB 的内存，而测试服务也许无法满足，这便是问题。回收周期从传统上讲，PHP 以往使用的引用计数内存机制，无法定位循环引用内存泄露，然而自 5.3.0 起，PHP 通过实现 引用计数系统中的并发周期回收(Concurrent Cycle Collection in Reference Counted Systems) 的同步算法来解决了这个问题。虽然对算法的完全说明有点超出这部分内容的范围，但基本的解释是有的。首先我们要建立一些基本原则。如果 &quot;refcount&quot; 增加了，zval 容器仍在被使用，所以这不是垃圾。如果 &quot;refcount&quot; 被减少了，并且被减至 0，则 zval 可以被释放。这意味着，只有当 &quot;refcount&quot; 被减少至非零时，垃圾周期 (garbage cycles) 才可以被产生。其次，在一次垃圾周期中，是有可能通过判断 &quot;refcount&quot; 是否可以被减 1，以及哪些 zval 的 &quot;refcount&quot; 是 0 的方式，来发现垃圾的。为避免发生检查所有 refcount 可能减少的垃圾周期，该算法把所有可能的root (possible roots)，即 zval 放进 &quot;root buffer&quot; (以紫色示意) 中。同时也确保每个可能是垃圾的 root 在 root buffer 中只出现一次。只有当 root buffer 达到饱和，回收机制才会对里面所有不同的 zval 启动。详见上图步骤 A。在步骤 B 中，算法针对所有可能的 root 执行一次深度优先搜索，找到 zval 后对其 refcount 减 1，并确保不会在同一个 zval 上重复执行 (以灰色示意)。在步骤 C 中，算法再次对每个 root 节点进行深度优先搜索，再次检索每个 zval 的 refcount 值。如果发现 refcount 为 0，zval 则被标记成 &quot;白色&quot; (蓝色部分)。如果 refcount 大于 0，则算法将从此处执行深度优先搜索并回滚 refcount 减 1 操作，并将这些 zval 重新标记为 &quot;黑色&quot;。在最后的步骤 D 中，算法遍历整个root buffer，从中移除 zval root，同时检索出之前步骤中被标记为 &quot;白色&quot; 的 zval。每个被标记为 &quot;白色&quot; 的 zval 都将被释放。现在你对算法是如何工作已经有了基本的认识，我们回过头来看它是如何与PHP集成的。默认情况下，PHP 的垃圾回收机制 (garbage collector) 是开启的。然而 php.ini 配置文件允许你做出修改: zend.enable_gc。当 GC 开启时，一旦 root buffer 达到饱和，上述的循环查找算法就会被执行。root buffer 固定可存放 10,000 个 root (虽然你可以通过修改位于 PHP 源码 Zend/zend_gc.c 中的 GC_ROOT_BUFFER_MAX_ENTRIES 常量，然后重编译 PHP 来改变这个数值)。当 GC 关闭时，循环查找算法将不会启动。然而，可能的 root 将永远记录在 root buffer 里，不管是否在配置中开启了 GC。如果在 GC 关闭的情况下， root buffer 达到饱和，后续的可能的 root 就不会被记录下来。那些无法被记录的可能的 root 将永远无法被算法分析。如果它们存在循环引用，他们讲永远无法被清理掉，并造成内存泄露。为什么在GC关闭的情况下，还是会有 root 被记录呢？是因为记录这些 root 要比在每次找到root时判断GC是否开启更快。然而，垃圾回收与分析机制本身可能会消耗相当长的时间。除了修改 zend.enable_gc 配置，同样也可以通过调用 gc_enable() 或 gc_disable() 来控制垃圾回收机制的开与关。调用这些函数和修改配置是等效的。这同样也可以用来强制控制垃圾回收即便 root buffer 尚未饱和。你可以使用 gc_collect_cycles() 函数实现。该函数将返回被算法收集的周期数量。允许打开和关闭垃圾回收机制并且允许自主初始化的原因，是由于你的应用程序的某部分可能是高时效性的。在这种情况下，你可能不想使用垃圾回收机制。当然，对你的应用程序的某部分关闭垃圾回收机制，是在冒着可能发生内存泄漏的风险，因为一些可能 root 也许存不进有限的 root buffer。因此，就在你调用 gc_disable() 函数释放内存之前，先调用 gc_collect_cycles() 函数可能比较明智。因为这将清除已存放在 root buffer 中的所有可能 root，然后在垃圾回收机制被关闭时，可留下空 buffer 以有更多空间存储可能 root。]]></content>
      <categories>
        <category>笔记</category>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库 InnoDB 学习笔记]]></title>
    <url>%2F2019%2F07%2F04%2FMySQL-%E6%95%B0%E6%8D%AE%E5%BA%93-InnoDB-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[记录最近对MySQL学习的一些总结。索引聚合索引主键字段的索引就是聚合索引，索引中保存了整行记录的所有字段值辅助索引其他字段的索引就是辅助索引，辅助索引仅仅保存了记录行的主键值(id) 和当前索引的字段。索引覆盖(覆盖索引)一般来说，当执行 select * from user where age = 10; 时，如果 age 字段添加了 B+TREE 索引， 则 MySQL 会先通过辅助索引查找到记录的 id，再通过聚合索引最终查找到数据行各字段的值。 但如果查询语句中只去查询索引中包含的字段，查询时就只需通过辅助索引定位，拿到索引字段值后将结果返回即可， 不用再去查找聚合索引，这样就实现了索引覆盖。当然，如果查询语句中还同时包含主键字段 (id) ，那也同样可以实现索引覆盖。索引建立的几大原则最左匹配索引会从where 语句开始，从左到右进行匹配，直到遇到范围查询 (&gt;，&lt;，!=，like，between) 时，匹配将会停止。 在 a = 1 and b = 2 and c &gt; 3 and d = 4 语句中，建立联合索引 (a, b, c, d)，此时 字段 d 是无法用到索引的，因为 c &gt; 3 是范围查询， 索引匹配到这里就停止了。如果将联合索引的顺序调整为 (a, b, d, c) 则可以用到索引， 因为上述的 where 语句等效于 a = 1 and b = 2 and d = 4 and c &gt; 3 这个顺序和索引一致，虽然有范围查询但那已经是最后一个条件了。 我们不用手动去调整 where 中条件的顺序，MySQL 查询优化器会自动调整条件位置，以尽可能地使用索引。= 之间可以乱序由于 MySQL 查询优化器会自动调整条件位置，以尽可能地使用索引，所以在有索引 (a, b, c) 的情况下，a = 1 and c = 3 and b = 2 这样的语句也是可以使用索引的。尽量选择区分度高的字段来添加索引区分度是指一个字段的值在记录中去重后的数量比上所有记录数量，表示这个字段值不重复的比例，即: count(distinct(&#39;column&#39;)) / count(*)， 在sql中一般可以这样来查看: select type, count(*) from t group by type。区分度越高则需要索引匹配的次数就越少，查询就越快速。 可以看出，表中主键的区分度固定为 1，而一些类型、状态等枚举字段将会在数据量逐渐增大情况下趋近与 0，这样的字段更适合添加 Hash 索引而不是 B+TREE。索引列不能参与计算，否则无法使用索引比如 from_unixtime(created_at) = &#39;2019-07-04 14:41:30&#39; 是不能使用 create_time 索引的，应换成这样: created_at = unix_timestamp(&#39;2019-07-04 14:43:11&#39;)事务术语概念脏读 (Dirty Read):事务中的修改，即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也被称作脏读。 例: A事务begin =&gt; B事务begin =&gt; B事务update某行 =&gt; A事务select该行，得到了更新后的结果不可重复读 (Unrepeatable Read):事务中的修改提交后，其结果被其他事务所读取到。 例: A事务begin =&gt; B事务begin =&gt; B事务update某行 =&gt;B 事务commit =&gt; A事务读取该行，得到了更新后的结果幻读 (Phantom Read):所谓幻读，指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行。 例: A事务begin =&gt; B事务begin =&gt; B事务insert =&gt; B事务commit =&gt; A事务select，得到了之前没有的数据 解决方式: 加锁 (乐观锁 / 悲观锁)。InnoDB 存储引擎通过多版本并发控制（MVCC）解决了幻读的问题。事务隔离级别脏读不可重复读幻读备注(未提交读) Read Uncommittedyyy性能好，但是会早成许多业务上的异常，一般不用(已提交读) Read Committednyy可以避免脏读，但是会出现不可重复读(可重复读) Repeatable ReadnnyInnoDB 默认的隔离级别，实际上已经通过 Next-Key 锁机制避免了幻读(串行化) Serializablennn性能消耗太大，一般不用 (select 时也会加锁)不可重复读和幻读的区别区别在于 不可重复读 是由 update 操作造成，而 幻读 是由 insert、delete 操作造成。 在 Read Committed 级别下，当执行sql读取到数据后，给这些记录加锁，让其他事务无法修改这些数据， 则实现了 可重复读。但是这种方法是无法阻止 insert 操作的，当事务A读取了数据，并修改了某些数据(加锁)， 事务B还是可以insert数据提交，这时A事务再次读取就会发现多出了之前没有的数据，这就是幻读，而且无法通过行锁来避免。乐观锁和悲观锁悲观锁悲观锁是有数据库本身提供的，具有良好的排他性。 在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时加锁，其它事务无法修改这些数据。乐观锁相比悲观锁，乐观锁要宽松一些，通常是通过版本(version)记录机制来实现的。何谓数据版本？即为数据增加一个版本标识， 在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 version 字段来实现 (MVCC)。 读数据时将 version 一起读取，更新时对 version +1，提交的时候，将提交的数据版本和数据库表对应记录的版本进行对比，如果提交数据的版本大于当前数据版本，则执行更新，否则认为是过期的数据，不更新。MVCC 在 InnoDB 中的实现在 MySQL 的 InnoDB 中，会在每行数据后添加两个额外的隐藏值来实现 MVCC，其中一个记录这条数据何时被创建，另一个记录这条数据何时过期(或者被删除)。 在实际操作中，存储的并不是时间，而是事务版本号。每开始一个新事务，版本号就会 +1。select 时，只读取&lt;=当前事务版本的数据insert / update / delete 时，更新数据的事务版本MVCC 解决了幻读的问题，然而却并不能阻止其他事务对数据的 insert，任然会引发数据冲突。要解决这个问题，需要对数据上锁。快照读与当前度在 Repeatalbe Read 级别下，MySQL 通过 MVCC 实现了快照读 (snapshot read)，即事务中普通的 select 语句只能读取到当下版本的数据。 然而update 等操作却读取的是最新版本的数据，也就是当前读 (current read)。在 MVCC 中:快照读: 普通的 select 语句，不会加锁select * from t1 ...当前读: 特殊的 select 语句和 insert / update / delete 语句，都会上锁select * from t1 where ... lock in share modeselect * from t2 where ... for updateinsert into ...update t1 set ...delete from t1 ...Next-Key锁Next-Key 锁是行锁和 GAP 锁(间隙锁)的结合。在 Repeatalbe Read 级别中，如果执行了索引查询并上锁，则会一同锁住索引两侧的数据(按索引字段排序)。 事务A执行 select * from user，其中 age 字段存在索引，其结果为:1234567+----+--------+---------+---------+-----+| id | name | address | other | age |+----+--------+---------+---------+-----+| 7 | name7 | chengdu | nothing | 7 || 13 | name13 | chengdu | nothing | 13 || 14 | name14 | chengdu | nothing | 14 |+----+--------+---------+-------+-------+这里假设 age 字段值在整个表中的排序为 ..., 7, 13, 14, ...。 事务A接着执行 select * from user where age = 13 lock in share mode 对数据上锁，输出:12345+----+--------+---------+---------+-----+| id | name | address | other | age |+----+--------+---------+---------+-----+| 13 | name13 | chengdu | nothing | 13 |+----+--------+---------+---------+-----+这时事务B想要插入数据，执行 insert into user values(0, &#39;name16&#39;, &#39;hxxi&#39;, &#39;woman&#39;, &#39;nothing&#39;, 12)，此时操作会被阻塞。 如果将刚才插入语句中的 age 字段值修改为一个 &gt;= 14 或者 &lt; 7 的值，结果会怎么样呢？执行 insert into user values(0, &#39;name16&#39;, &#39;hxxi&#39;, &#39;woman&#39;, &#39;nothing&#39;, 6)，输出:12Query OK, 1 row affectedTime: 0.012s这说明了事务A中的 select * from user where age = 13 lock in share mode 不仅锁住了满足条件的记录行， 也锁住了 age &gt;= 7 和 age &lt; 14 的记录，也就是区间 [7, 14)，这就是 Next-Key 锁的效果。 在上面例子里的 age 字段是有索引的，这点非常重要，因为如果没有索引的话，Next-Key 锁的范围将会锁住整个表， 即便是 insert into user values(0, &#39;name16&#39;, &#39;hxxi&#39;, &#39;woman&#39;, &#39;nothing&#39;, 6) 也会被阻塞。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>innodb</tag>
        <tag>lock</tag>
        <tag>transaction</tag>
        <tag>index</tag>
        <tag>database</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Drone 1.0 简单实践]]></title>
    <url>%2F2019%2F06%2F27%2FDrone-1.0-%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[本文仅针对 Drone 1.0 版本由于版本更新无法向下兼容，所有有必要自己从头实践一下。实现目标为：搭建 drone ci 服务器，配置nginx反代，实现https访问编写 .drone.yml 配置文件，实现 golang 项目的自动化部署，包括 build，依赖缓存，二进制发布(rsync)Drone CI 服务器搭建与访问我选用的是针对 GitHub 仓库的单机部署。 根据官方文档的说明，先进行 docker pull drone/drone:1 将镜像拉下来，然后配置 docker-compose.yml (官方只给出了 docker run 的启动方式，可能是因为 1.0 版本只需要启动一个容器吧)：1234567891011121314151617181920version: '3'services: ci: image: drone/drone:1 volumes: - /var/run/docker.sock:/var/run/docker.sock # 宿主机的路径不能变 - /var/lib/drone:/data # 宿主机路径可以是别的地方 environment: - DRONE_GITHUB_SERVER=https://github.com - DRONE_GITHUB_CLIENT_ID=github的clientID - DRONE_GITHUB_CLIENT_SECRET=github的clientSecret - DRONE_RUNNER_CAPACITY=2 - DRONE_USER_CREATE=username:DarthPestilane,admin:true # 指定管理员用户 - DRONE_SERVER_HOST=ci.yourhost.com # ci 服务器域名 - DRONE_SERVER_PROTO=https - DRONE_TLS_AUTOCERT=true - DRONE_LOGS_DEBUG=true # debug 日志级别 ports: - 8004:80 # 将端口暴露出来Drone CI 容器启动后，我们继续配置 nginx 反代：1234567891011121314151617server &#123; listen 443 ssl http2; server_name ci.yourhost.com; ssl_certificate /path/to/ci.yourhost.com/fullchain.pem; ssl_certificate_key /path/to/ci.yourhost.com/privkey.pem; location / &#123; proxy_pass http://172.17.0.1:8004; # 反代到 drone 服务，ip为 docker network bridge &#125;&#125;server &#123; # 强制 https listen 80; server_name ci.yourhost.com; return 301 https://ci.yourhost.com$request_uri;&#125;配置完成后，记得先要将域名和证书准备好，然后 restart nginx 容器。此时我们可以通过域名访问Drone CI了。配置 CI (.drone.yml)Drone 1.0版本的配置文件依然是 .drone.yml。我将 CI 步骤分为两步：build 和 deploy。Build最简单的配置：12345678910111213kind: pipelinename: drone-teststeps:- name: build image: golang environment: GOOS: linux GOARCH: amd64 CGO_ENABLED: 0 commands: - go build - go testCI 服务器会拉取 GitHub 仓库代码，并读取上述配置，然后根据配置执行对应的操作。这里 CI 会执行类似下面的命令：12345678docker run --rm \ --env=GOOS=linux \ # --env=... 其他环境变量 \ --volumes=`pwd`:/drone/src \ --workdir=/drone/src \ # workdir 也为 /drone/src --entrypoint=build.sh \ golang \ # your commands在容器内部会执行：12345#!/bin/shset -ego buildgo test执行完成后，如果命令不出错，就可以在宿主机上得到编译好的二进制文件。然而如果我的 golang 项目中包含了第三方依赖，按照这样的配置，每次 push 后执行 go build 是会重新通过网络下载依赖包的，因为宿主机本地没有保存依赖，以至于 build 时间太长(想想 npm install 😱)。 但了解了 CI 对容器的操作后，这个问题就迎刃而解了。更新配置：1234567891011121314# ...steps:- name: build image: golang volumes: - name: cache-go-deps path: /go # 容器内的路径 # ...#...volumes:- name: cache-go-deps host: path: /var/local/drone-cache/repo/go-cache # 宿主机的路径上面的配置中，我将宿主机的路径挂载到了容器内，实现了依赖缓存持久化，后面的 build 过程可以就可以使用依赖缓存了。Deploy实现了自动化 build 后，还需要实现自动化部署，即分发二进制。 在实际生产中，CI 服务器需要将 build 完成后的项目，发布到生产服务器上，这里我使用 rsync 来发布：1234567891011121314151617181920212223242526272829# ...steps:- name: build # ...- name: deploy image: drillster/drone-rsync environment: RSYNC_KEY: from_secret: rsync_key settings: user: admin hosts: - "prod01.host.com" - "prod02.host.com" ports: - 22 - 22 source: ./ target: /var/local/prod/ recursive: true delete: true include: - drone-test exclude: - "**.*" script: - /var/local/prod/drone-test#...通过上面的配置文件，drone 会将容器中的 ./ 目录（其中的内容和宿主机相同）下的指定文件分别同步到两个生产服务器中的 /var/local/prod/ 目录中，并登录生产服务器，执行指定的 scripts。这些操作的前提是要允许 CI 服务器够通过 ssh 的文件秘钥方式登录到生产服务器，那么首先我需要确保 CI 宿主机本身可以登录到生产服务器。 在CI 宿主机上执行 ssh-keygen 命令，生成公钥和私钥(id_rsa, id_rsa.pub)，然后将公钥内容拷贝到生产服务器的 ~/.ssh/authorized_keys 文件中，这样一来在 CI 宿主机上就可以登录到生产服务器了。然而我最终的目标是要在 Drone CI 的容器中实现 ssh 登录，有个很直接的方法就是直接将宿主机私钥填写在 .drone.yml 配置里，但是这样做太危险了，好在 Drone 1.0 版本可以通过 Web UI 来添加私密信息键值对(key-secret)，于是我在 Web 界面中配置了 rsync_key，并将这个名称引用在 .drone.yml 中，这样就安全了！ 关于 drillster/drone-rsync 镜像的更多配置参数，可以参考它的 Docs===至此，整个 CI 配置已经大部分完成了，再加上一些 git pull 和触发条件的配置(triggers)，整个 .drone.yml 看起来是这样的：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152kind: pipelinename: drone-testclone: depth: 10trigger: branch: - master # 只有在master分支的变动，才会触发 CIsteps:- name: build image: golang environment: GOOS: linux GOARCH: amd64 CGO_ENABLED: 0 volumes: - name: cache-go-deps path: /go # 容器内的路径 commands: - go build - go test- name: deploy image: drillster/drone-rsync environment: RSYNC_KEY: from_secret: rsync_key settings: user: admin hosts: - "prod01.host.com" - "prod02.host.com" ports: - 22 - 22 source: ./ target: /var/local/prod/ recursive: true delete: true include: - drone-test exclude: - "**.*" script: - /var/local/prod/drone-testvolumes:- name: cache-go-deps host: path: /var/local/drone-cache/repo/go-cache # 宿主机的路径]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>CI</tag>
        <tag>Drone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iPhoneXS Jailbreak]]></title>
    <url>%2F2019%2F05%2F21%2FiPhoneXS-jailbreak%2F</url>
    <content type="text"><![CDATA[起因手中的 iPhone XS 为了这次越狱，一直坚持停留在 iOS12.1 版本，不过也没什么升级动力。昨天惊喜地发现 YouTube 上有人上传了 Top 75 Best FREE iOS 12.1.2 Jailbreak Tweaks! A12 Compatible Tweaks! 视频，满怀期待地点进去看，果然是有越狱工具 release 了！开始越狱根据视频里的内容，使用 Chimera 作为越狱工具，在手机上安装好后，就可以直接一键越狱了。刚开始没注意到可以在已知漏洞中选择一个作为越狱方式，而直接点了 Jailbreak 按钮，结果中途重启了好几次，但最终也完成了越狱，并且安装上了 Sileo（Cydia 的替代品）。后来的折腾中，发现使用 m***2 这个漏洞，可以非常顺滑地完成越狱，不会遇到重启。插件安装完成越狱后，非常兴奋地点开 Sileo，但是却出现了让我耗费许多时间才得以解决的问题。Sileo 无法更新源列表，一刷新就会报404的错，这样一来就几乎无法安装任何插件。 Google 了一番也没看见靠谱的解决方法，看了好多无非都是让你重新越狱，或者让你打开 Sileo 的网络权限，可是这个时候的 Sileo 根本不会出现在网络权限app列表中。于是继续 Google，终于找到了解决方案：使用爱思助手，下载 乐网 到手机上打开 乐网 使用全局模式此时打开 Sileo 就可以刷新源列表了！后来就可以在网络权限里找到 Sileo 了！OK，既然 Sileo 可以正常联网了，已经迫不及待地想去安装插件了，但是又遇到了另一个棘手的问题。当成功安装好插件并完成 respring 后，插件既没有生效，而且也不会在 设置 中显示该插件选项，于是又开始 Google，又尝试了很多没有用的方法，比如重新安装 rockebootstrap、preferenceLoader 等插件，其实这些插件已经是最新版本了。最后通过 ssh 连上手机，找到插件的配置文件的位置，并手动拷贝到另一个目录下才得以解决：首先使用 ssh 连接到手机：ssh root@your_ip，初始密码是 alpine，登录后记得马上把密码改了。经过简单的探索，发现安装后的插件的配置文件（.plist 和 .dylib）都会存放在 /Library/MobileSubstrate/DynamicLibraries 目录下，而要想使插件生效，则需要将这些配置文件放到 /Library/TweakInject 目录中，于是手动 copy 并 respring 后，所有插件都生效了，并且其选项也出现在 设置 中。这个问题的出现可能来自于越狱工具本身，其现象是没有自动复制插件的配置到正确路径。虽然插件可以正常使用了，但是按照这样手动 copy 的方式来完成插件的安装是很不方便的，依然需要思考更好的方案。其实很容易就发现 /Library/TweakInject 这个目录是个软链接，target 是 /usr/lib/TweakInject，也就是说插件的配置文件最终都被 copy 到了这里。于是我将 /Library/MobileSubstrate/DynamicLibraries 备份后，也做成了软链接，target 也是 /usr/lib/TweakInject，respring 后安装了一个新的插件，结果新插件成功生效，原有的插件依然可用！至此，插件安装的问题算是成功解决了。感想越狱成功，挺高兴的，因为可以安装许多有用的插件了，这些插件将iOS系统变得更加方便顺手。此时想起一句话：越狱之后，iOS才能发挥出它真正的强大。使用 Chimera 越狱，体验是很好的，不过还是存在bug，比如 Sileo 网络权限问题和插件安装问题，解决方法都挺简单但是搜索方法的过程就不太容易了，不能立马Google到，这或许也反映出越狱的需求真的在逐渐减少。然而 Sileo 相比 Cydia 实在是好太多了，至少是这个时代的产品，而 Cydia 明显已经过时了。想想上一次越狱还是2015年左右，当时用的是 iPhone 5c，iOS 版本是 7.x，那时的越狱体验是真的好啊，尤其是盘古，一次性成功，完美越狱，插件可用，不需要折腾。虽然现在处于半完美越狱状态，重启之后将恢复到非越狱状态，但在我看来这也是一种不错的选择。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>jailbreak</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次群晖 SHR 降级折腾]]></title>
    <url>%2F2019%2F04%2F01%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BE%A4%E6%99%96-SHR-%E9%99%8D%E7%BA%A7%E6%8A%98%E8%85%BE%2F</url>
    <content type="text"><![CDATA[背景硬件:NAS: 群晖DS218+(双盘位) 系统版本: DSM 6.2.1-23824 Update 1硬盘: 2T希捷酷狼 x 2移动硬盘: 1T希捷由于在最初安装DSM时，系统自动选择了SHR冗余模式，使得其中一块硬盘变成了数据保护盘，实际可用的容量只有2T。 随着下载的电影，以及上传照片和其他文件的数量增加，NAS空间使用率已高达95%+。若要给空间扩容，无非是两种策略:将原有的两块硬盘整体换为更大容量的2块硬盘将系统原先设定的SHR冗余模式降级为basic模式(无数据冗余保护)，归还硬盘空间由于NAS空间中的大部分体积被电影所占用，相比之下真正重要的文件--比如照片，生活视频，工作文件等--数量相对较少。 经过思考，决定采取第二种解决方案，即SHR降级，并配合外接USB存储设备，对重要文件进行冷备份。准备将移动硬盘通过USB和NAS连接，可先将硬盘格式化为NTFS格式。File Station应用中会新增usbshare1-1和usbshare1-2两个共享文件夹。通过查看容量空间，找到可用的那一个(usbshare1-2)。将重要数据备份到移动硬盘中，比如照片。SHR降级步骤在NAS运行状态下取出一块硬盘，取出后，在存储空间管理员应用中的存储空间上会显示堪用字样，此时NAS机器会发出警报声，但可以关闭。将取出的硬盘插回去，此时该硬盘处于未初始化状态。新增存储空间，此时可以手动选择RAID类型。按照提示，选择basic模式，逐步完成创建。打开控制面板，将所有的共享文件夹，迁移至新的存储空间中，过程中可能需要停用一些应用程序。迁移完成后，堪用存储空间对应的硬盘拔出，并重新插入，然后按照上述方法新增存储空间。如果无法识别硬盘，则重启NAS。(也许可以不用拔硬盘，直接删除存储空间并新增...)现在已经有2个存储空间了，可以根据需求，迁移共享文件夹。修复或重新安装NAS套件。数据冷备份编写冷备份脚步，使用rsync:123456#!/bin/shecho "started to sync photo.";rsync -avzh --exclude='@eaDir' --exclude='.DS_Store' --delete /volume2/photo/ /volumeUSB1/usbshare1-2/photo/;echo "started to sync video.";rsync -avzh --exclude='@eaDir' --exclude='.DS_Store' --delete /volume2/video/ /volumeUSB1/usbshare1-2/video/;将脚本添加到定时任务中。结束整个过程可能会耗费数小时，不过群晖NAS套件体验是非常好的，很多功能都能轻松实现。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>NAS</tag>
        <tag>群晖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql函数运用]]></title>
    <url>%2F2019%2F01%2F09%2FMysql%E5%87%BD%E6%95%B0%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[自从MySQL更新到v5.7以后，支持了json类型数据，使得在项目中存储弱业务逻辑的结构数据变得尤为简单，同时也提供了许多内置json操作函数，如 JSON_SET，JSON_EXTRAT等。 然而如果想要修改json字段中的某个元素内容，可能不会简单到一条 update 语句。比如现在有这样一个json数据:123456[ &#123;"name": "Jack", "age": "18"&#125;, &#123;"name": "John", "age": "20"&#125;, &#123;"name": "Benn", "age": 22&#125;, // ...]很明显，上面的json数组中的某些对象的age属性值错误的存为了字符串，如果我们想要将age转换为整数，不管是写多么复杂的子查询恐怕都无法完成， 因为MySQL目前还没有可以遍历json数组的方法。这时我们可以写一个简单的函数来解决这样的问题，比如这样：12set @j = '[&#123;...&#125;, &#123;...&#125;, ...]';select fixJsonArr(@j);在创建函数之前记得修改定界符：1mysql&gt; DELIMITER $$;创建一个函数：1234CREATE FUNCTION `fixJsonArr`(objArr JSON) RETURNS jsonBEGIN -- TODOEND于是我们定义了一个函数，名为fixJsonArr，他将接收一个json类型参数，经过处理后返回一个json类型的数据。接下来我们需要遍历整个json数组：12345678910-- context ...BEGIN DECLARE i int default 0; WHILE i&lt; json_length(objArr) do -- Loop -- TODO select i+1 into i; -- i++ END WHILE;END上面的代码中我们用到了json_length内置函数，它将返回json数组的长度，用于遍历循环操作。 我们使用select i+1 into i;的方式来实现i的自增，从而控制循环的结束时机，也为后面的逻辑实现变量赋值的效果。接下来我们要做的就是拿到age属性的值，并且转换为整数类型：123456789101112-- context ...BEGIN DECLARE i int default 0; DECLARE age int default 0; WHILE i &lt; json_length(objArr) do -- Loop select cast(json_extract(objArr, CONCAT('$[', i ,'].age')) as unsigned) into age; -- TODO select i+1 into i; -- i++ END WHILE;END转换成为整数后，我们将使用json_set方法去修改原本的json数组：12345678910111213-- context ...BEGIN DECLARE i int default 0; DECLARE age int default 0; WHILE i &lt; json_length(objArr) do -- Loop select cast(json_extract(objArr, CONCAT('$[', i ,'].age')) as unsigned) into age; select json_set(objArr, CONCAT('$[', i ,'].age'), age) into objArr; select i+1 into i; -- i++ END WHILE; -- TODO returnEND最后我们只需要返回修改后的json数组即可完成此函数，整个函数看起来将会是这样：12345678910111213CREATE FUNCTION `fixJsonArr`(objArr JSON) RETURNS jsonBEGIN DECLARE i int DEFAULT 0; DECLARE age int DEFAULT 0; WHILE i &lt; json_length(objArr) DO select cast(json_extract(objArr, CONCAT('$[', i ,'].age')) as unsigned) into age; select json_set(objArr, CONCAT('$[', i ,'].age'), age) into objArr; select i+1 into i; END WHILE; RETURN objArr;END运用：1update tb set JsonCol = fixJsonArr(JsonCol) where ...;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh隧道转发]]></title>
    <url>%2F2018%2F11%2F26%2Fssh%E9%9A%A7%E9%81%93%E8%BD%AC%E5%8F%91%2F</url>
    <content type="text"><![CDATA[使用ssl隧道，将内网中的服务转发到本地端口语法：1ssh -N -L 本地端口:内网host:内网端口 user@server-host示例：1ssh -N -L 3316:10.0.1.2:3306 user@remote.server.com将remote.server.com中部署在内网10.0.1.2的服务器连接转发到本地3316端口。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Welcome Home (Sanitarium)]]></title>
    <url>%2F2018%2F09%2F07%2FWelcome-Home-Sanitarium%2F</url>
    <content type="text"><![CDATA[Welcome to where time stands still 欢迎来到时间静止的地方No one leaves and no one will 没有人离开，也没有人会离开Moon is full, never seems to change 一轮满月，恒古不变Just labeled mentally deranged 随意地被贴上精神错乱的标签Dream the same thing every night 每夜做相同的梦I see our freedom in my sight 梦见我们的自由No locked doors, no windows barred 没有锁住的门，没有封住的窗No things to make my brain seem scarred 不会让我的大脑伤痕累累Sleep my friend and you will see 睡吧，我的朋友，你会发现That dream is my reality 梦即是现实They keep me locked up in this cage 他们把我锁在这牢笼里Can&#39;t they see it&#39;s why my brain says Rage? 他们难道看不见这是为什么我脑子喷出怒火?Sanitarium, leave me be 疯人院，离开我Sanitarium, just leave me alone 疯人院，别来烦我Build my fear of what&#39;s out there 外面的未知让我恐惧And cannot breathe the open air 无法呼吸Whisper things into my brain 喃喃自语Assuring me that I‘m insane 确信我已经疯掉They think our heads are in their hands 他们认为我们的人头在他们手掌中But violent use brings violent plans 但是使用暴力只会带来暴力的计划Keep him tied, it makes him well 绑住他，就是让他变好的办法Hes getting better, can&#39;t you tell? 他正在变好，你难道看不出来？No more can they keep us in 他们再也不能把我们抓进去Listen, damn it, we will win 妈的，给我听好，我们一定会胜利They see it right, they see it well 在他们开来这都是好的、对的But they think this saves us from our Hell 可他们觉得这样是将我们从我们的地狱里救出Sanitarium, leave me be 疯人院，离开我Sanitarium, just leave me alone 疯人院，别来烦我Fear of living on 对活下去的恐惧Natives getting restless now 当地人现在变得焦躁不安Mutiny in the air 反叛声在空气里回荡Got some death to do 要做些毁灭的事Mirror stares back hard 镜子中的眼神凌厉Kill, it&#39;s such a friendly word 杀戮是多么友善的词汇Seems the only way 像是唯一的方法For reaching out again 再次逃出生天]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>Metallica</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[certbot更新证书]]></title>
    <url>%2F2018%2F08%2F23%2Fcertbot%E6%9B%B4%E6%96%B0%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[一键更新证书的脚步，适用于docker容器中的nginx1234567891011121314151617#!/bin/sh# usage:# ./cert.sh &lt;certonly|renew&gt;cd $(dirname "$0"); # 到当前目录下docker-compose stop nginxdocker run -it --rm --name certbot \ -v "/etc/letsencrypt:/etc/letsencrypt" \ -v "/var/lib/letsencrypt:/var/lib/letsencrypt" \ -p 80:80 \ -p 443:443 \ certbot/certbot "$@"docker-compose up -d]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx+FPM配置]]></title>
    <url>%2F2018%2F05%2F30%2FNginx-FPM%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[记录下nginx+fpm的配置，适用于laravelnginx.conf123456789101112131415161718192021222324252627282930user nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; # servers starts here server &#123; listen 8080; server_name localhost; root /var/www/project; include ./fpm.conf; &#125;&#125;fpm.conf123456789101112index index.php index.html index.htm;location / &#123; try_files $uri $uri/ /index.php?$query_string;&#125;location ~ \.php$ &#123; fastcgi_pass fpm:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params;&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>nginx</tag>
        <tag>fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Happy Birthday!]]></title>
    <url>%2F2018%2F05%2F03%2FHappy-Birthday%2F</url>
    <content type="text"><![CDATA[生日快乐！ 今天（2018-05-03）是你阳历生日，24岁，生命中的第二个本命年，希望可以愉快的度过这一年。很遗憾，以我们目前所处的环境，能邀请到的朋友实在太少，从而没有办法举办你想要的生日趴。 遥想大学时光，身边总有好多要好的朋友，甚至每周都可以出来聚一次，不管做什么都是快乐的。 毕业之后，各奔东西，还在同一座城市的伙伴太少了。 你也常常在我耳边说，如今能约出来的人越来越少了。 我也认为我们需要结交一些新的朋友，多接触一些社会各个层面的人。 然而自从我离开大学校园之后，却很找到志同道合、趣味相投的人；也不太愿意带着目的去结交朋友，而且也不知道对方是否也是带有目的。 不过仍需努力，不仅是为了生日趴，也为了我们的未来生活。都说本命年不好过，不过就我觉得这个本命年一定是幸福快乐的，因为不久之前，我们都找到了新的工作，都涨了工资，哥哥也一岁了，健康好动。 良好的开头已经具备了，成功的一半已经达成了！ 本命年来之不易，希望我们都能记得这一年。 时光飞逝，不知不觉我们在一起已经超过4年了，我们的脸庞已由当年的青涩，逐渐变得沉稳，爱你的心也越发深沉坚定。 许多开心和难过的时刻都历历在目，非常感谢和庆幸这一路有你相伴，给与我鼓励和支持，让我成为更好的自己。我愿意陪你走过剩下的本命年，不知你是否也愿意陪我（愿意） 😂。 希望你也可以变成更好的自己，生日快乐！]]></content>
      <categories>
        <category>感情</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[搭建简单的nginx文件服务]]></title>
    <url>%2F2018%2F04%2F25%2F%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84nginx%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[在没有提供第三方存储服务的时候，可以先用NGINX做一个简单的本地存储服务，最终也能很方便地实现通过 GET /archives/abc/efg/hij/hash.png 方式访问文件。Here we go.配置 nginx.conf：123456789101112131415161718192021222324252627282930313233343536373839404142user nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; access_log /var/log/nginx/access.log main; sendfile on; # tcp_nopush on; keepalive_timeout 65; gzip on; gzip_proxied any; gzip_types *; gzip_comp_level 6; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; server &#123; listen 80; location /archives/ &#123; alias /var/www/files/; autoindex off; &#125; &#125;&#125;重点在于：1234location /archives/ &#123; alias /var/www/files/; autoindex off;&#125;这里用的是 alias 指令而并非 root。两者的区别在于：In case of the root directive, full path is appended to the root including the location part, whereas in case of the alias directive, only the portion of the path NOT including the location part is appended to the alias. https://stackoverflow.com/questions/10631933/nginx-static-file-serving-confusion-with-root-alias重启nginx后，访问 localhost/archives/path/to/file.png 即可访问 /var/www/files/path/to/file.png 文件 注意一点，alias 参数的末尾斜杠是必须添加的！如果要用 root 指令，那么就需要配置重写规则了：12345location /archives/ &#123; autoindex off; root /var/www/files; rewrite /archives/(.*) /$1 break;&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Unforgiven II]]></title>
    <url>%2F2018%2F04%2F16%2FThe-Unforgiven-II%2F</url>
    <content type="text"><![CDATA[The Unforgiven IILay beside me 躺在我身边Tell me what they&#39;ve done 向我讲述他们的所作所为to make my demons run 来赶走我的心魔The door is locked now 上了锁的门but it&#39;s open if you&#39;re true 会因为你的真诚而打开If you can understand the me 如果你可以理解面前的这个我then i can understand the you 那我也可以理解面前的这个你Lay beside me 躺在我身边under wicked sky 在邪恶的天空下The black of day, dark of night 白天的黑, 夜晚的暗We share this paralyze 我们都麻木不仁The door cracks open 门突然打开Black heart scarring darker still 内心更加黑暗but there&#39;s no sun shining through 没有阳关照射No, theres no sun shining 根本没有阳光What ive felt 我所感受的What ive known 我所了解的Turn the pages 翻开书卷Turn the stone 搬开石头Behind the door 我的心门should I open it for you? 是否应该为你打开?What ive felt 我所感受的What ive known 我所了解的Sick and tired 伤痛和疲惫I stand alone 我独自承担Could you be there? 你会在那儿吗?Cause I&#39;m the one who waits for you 因为我是一直在等待你的人Or are you unforgiven too? 或者你也不可饶恕?Come lay beside me 过来吧, 趟在我身边This won&#39;t hurt, I swear 我发誓不会有伤害She loves me not 也许她不爱我She loves me still 也许她还爱我But she&#39;ll never love again 但都永远不会再爱了She lays beside me 她趟在我身边but she&#39;ll be there when I&#39;m gone 不过当我离去的时候, 她会在那边Black heart scarring darker still 内心更加黑暗Yes, she&#39;ll be there when I&#39;m gone 是的, 当我离去的时候她会在那边Dead sure she&#39;ll be there 一定会在What ive felt 我所感受的What ive known 我所了解的Turn the pages 翻开书卷Turn the stone 搬开石头Behind the door 我的心门should I open it for you? 是否应该为你打开?What ive felt 我所感受的What ive known 我所了解的Sick and tired 伤痛和疲惫I stand alone 我独自承担Could you be there? 你会在那儿吗?Cause I&#39;m the one who waits for you 因为我是一直在等待你的人Or are you unforgiven too? 或者你也不可饶恕?Lay beside me 趟在我身边Tell me what I&#39;ve done 向我讲述我的所作所为The door is closed, so are your eyes 你闭着的双眼，如同关上的门But now I see the sun 不过我现在看见了太阳Yes, now I see it 是的, 我看到了What ive felt 我所感受的What ive known 我所了解的Turn the pages 翻开书卷Turn the stone 搬开石头Behind the door 我的心门should I open it for you? 是否应该为你打开?What ive felt 我所感受的What ive known 我所了解的Sick and tired 伤痛和疲惫I stand alone 我独自承担Could you be there? 你会在那儿吗?Cause I&#39;m the one who waits for you 因为我是一直在等待你的人Or are you unforgiven too? 或者你也不可饶恕?]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>Metallica</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang中slice的一些helper]]></title>
    <url>%2F2018%2F02%2F28%2FGolang%E4%B8%ADslice%E7%9A%84%E4%B8%80%E4%BA%9Bhelper%2F</url>
    <content type="text"><![CDATA[最近在用golang写业务代码，没有用框架，所以自己写的一些 helper 来辅助开发。这里分享下 slice 相关的 helper 。SliceDiff目的用于比较两个相同类型的slice，并找到不同的部分设计最初设计是只接收2个参数，然后返回一个[]interface{}，但是这样的返回意味着面临断言的可能，所有决定用反射优化下。 函数将接收3个参数，都为slice。第一个是原本的slice，第二个参数是用于和第一个slice做比较，比价之后的结果将会存入第三个参数中，所以第三个参数必须是个指针slice。 同时也兼容了空slice的情况，如果第一个参数是个空的slice，则直接return，跳过后续计算。 如果参数存在问题，比如类型不统一、第三个参数不是指针，会直接panic 😱 。 没有返回值。代码实现12345678910111213141516171819202122232425262728293031323334func SliceDiff(main, compared, result interface&#123;&#125;) &#123; mainValue := reflect.Indirect(reflect.ValueOf(main)) comparedValue := reflect.Indirect(reflect.ValueOf(compared)) if mainValue.Type() != comparedValue.Type() &#123; panic(errors.New("main's and compared's types should be the same")) &#125; resultValue := reflect.ValueOf(result) if resultValue.Kind() != reflect.Ptr &#123; panic(errors.New("result should be a slice ptr")) &#125; resultSlice := resultValue.Elem() if resultSlice.Kind() != reflect.Slice &#123; panic(errors.New("result should be a slice ptr")) &#125; mainLen := mainValue.Len() if mainLen == 0 &#123; return &#125; comparedLen := comparedValue.Len() nSlice := reflect.New(resultSlice.Type()).Elem() for i := 0; i &lt; mainLen; i++ &#123; var found bool for j := 0; j &lt; comparedLen; j++ &#123; if reflect.DeepEqual(mainValue.Index(i).Interface(), comparedValue.Index(j).Interface()) &#123; found = true break &#125; &#125; if !found &#123; nSlice = reflect.Append(nSlice, mainValue.Index(i)) &#125; &#125; resultSlice.Set(nSlice)&#125;示例123var diff []intSliceDiff([]int&#123;1, 2, 3, 4&#125;, []int&#123;1, 2&#125;, &amp;diff)fmt.Println(diff) // []int&#123;3, 4&#125;SliceUnique目的对slice中的元素去重设计函数只需接收一个参数，即要进行去重的slice指针。 然后由函数实现去重并覆盖原slice。 如果参数的类型不正确，会直接panic 😱。代码实现123456789101112131415161718192021func SliceUnset(slicePtr interface&#123;&#125;, index int) &#123; value := reflect.ValueOf(slicePtr) if value.Kind() != reflect.Ptr &#123; panic(errors.New("should be a slice ptr")) &#125; slice := value.Elem() nSlice := reflect.New(slice.Type()).Elem() if slice.Kind() != reflect.Slice &#123; panic(errors.New("should be a slice ptr")) &#125; l := slice.Len() if l == 0 &#123; return &#125; for i := 0; i &lt; l; i++ &#123; if i != index &#123; nSlice = reflect.Append(nSlice, slice.Index(i)) &#125; &#125; slice.Set(nSlice)&#125;示例123var s := []int&#123;1, 2, 3, 1, 3, 2&#125;SliceUnique(&amp;s)fmt.Println(s) // []int&#123;1, 2, 3&#125;to be continued...]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速获取当前内网IP的命令]]></title>
    <url>%2F2018%2F02%2F24%2F%E5%BF%AB%E9%80%9F%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E5%86%85%E7%BD%91IP%E7%9A%84%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1ifconfig | sed -En 's/127.0.0.1//;s/.*inet (addr:)?(([0-9]*\.)&#123;3&#125;[0-9]*).*/\2/p']]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang并发编程最简单实践]]></title>
    <url>%2F2018%2F01%2F18%2FGolang%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9C%80%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[不管怎么样，还是要学下并发编程的。这次在 golang 上学习。下面记录一下一个最简单的例子：golang 版本: version: 1.9.2 文件名：playground.go12345678910111213141516171819202122232425262728293031323334353637package mainimport ( "fmt" "time")func main() &#123; fmt.Println("begins at", time.Now().Format("2006-01-02 15:04:05")) chMap := map[string]chan interface&#123;&#125;&#123; "big": make(chan interface&#123;&#125;), "medium": make(chan interface&#123;&#125;), "small": make(chan interface&#123;&#125;), &#125; go bigFetch(chMap["big"]) go mediumFetch(chMap["medium"]) go smallFetch(chMap["small"]) for _, ch := range chMap &#123; fmt.Println(&lt;-ch) &#125; fmt.Println("ends at", time.Now().Format("2006-01-02 15:04:05"))&#125;func bigFetch(ch chan interface&#123;&#125;) &#123; time.Sleep(3 * time.Second) ch &lt;- "complete a big fetch costing 3 seconds"&#125;func mediumFetch(ch chan interface&#123;&#125;) &#123; time.Sleep(2 * time.Second) ch &lt;- "complete a medium fetch costing 2 seconds"&#125;func smallFetch(ch chan interface&#123;&#125;) &#123; time.Sleep(1 * time.Second) ch &lt;- "complete a small fetch costing 1 seconds"&#125;执行一下：12345678$ go run playground.go# output:begins at: 2018-01-18 15:35:57complete a small fetch costing 1 secondscomplete a big fetch costing 3 secondscomplete a medium fetch costing 2 secondsends at: 2018-01-18 15:36:00由上面的例子可以看出，并发编程的一个最基本的优势：节约时间！ 如果将上面的例子换成同步执行，则耗时应该是 1 + 2 + 3 = 6s，而并发处理只需要 max(1, 2, 3) = 3s。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让 `git status` 命令正确显示中文]]></title>
    <url>%2F2018%2F01%2F17%2F%E8%AE%A9-%60git-status%60-%E5%91%BD%E4%BB%A4%E6%AD%A3%E7%A1%AE%E6%98%BE%E7%A4%BA%E4%B8%AD%E6%96%87%2F</url>
    <content type="text"><![CDATA[环境是 macOS 。每当使用 git status 时，只要修改了带有中文的文件，在控制台输出的中文部分都会被转义成 Unicode ，阅读体验不太好。为了更好的体验，我修改了 git 的一个核心设置: git config --global core.quotepath false ，从此，再无困扰。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ide-helper提升PHPstorm开发laravel/lumen项目体验]]></title>
    <url>%2F2018%2F01%2F17%2F%E4%BD%BF%E7%94%A8ide-helper%E6%8F%90%E5%8D%87PHPstorm%E5%BC%80%E5%8F%91laravel-lumen%E9%A1%B9%E7%9B%AE%E4%BD%93%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[目前 phpstorm 应该是公认的开发 PHP 最好的 IDE 了，但在开发 laravel/lumen 项目时，由于框架实现方式问题，其代码提示功能被迫减弱。 为了更好的开发体验，在GitHub上有个 barryvdh/laravel-ide-helper 项目，目的就是弥补部分被削弱的代码提示功能。使用方法是用 composer 安装完成后，注册 service，用 artisan 命令生产 ide-helper 文件。具体参考GitHub上的文档。其实我们最终只是需要生成得到的 ide-helper 文件，就可以达到增强代码提示功能的效果，于是用 shell 写了个简单的脚本来生成 lumen 项目的 ide-helper 。其思路是：首先备份 composer.json 和 composer.lock 文件使用 composer 安装 ide-helper然后在 bootstrap/app.php 文件中追加注册 service 的代码（由于 macOS 下 sed 命令不太正常，所以用到了 gsed，通过 brew install gnu-sed 安装）接着执行 ./artisan ide-helper:generate 和 ./artisan ide-helper:meta 来生成 ide-helper 文件最后还原 bootstrap/app.php、 composer.json 和 composer.lock 文件以及对应的 composer 依赖1234567891011121314151617181920212223242526# lumen ide helper generatorlumen-helper-gen() &#123; # backup echo 'backup composer.*' cp composer.json composer.json.bak cp composer.lock composer.lock.bak # generate echo 'install ide-helper via composer' composer require --quiet --dev barryvdh/laravel-ide-helper echo 'edit bootstrap/app.php' l=`sed -n '/$app-&gt;register/=' bootstrap/app.php | tail -1` gsed -i.bak "$l a \$app-&gt;register(\\\Barryvdh\\\LaravelIdeHelper\\\IdeHelperServiceProvider::class);" bootstrap/app.php unset l echo 'generate ide-helper files' ./artisan ide-helper:generate ./artisan ide-helper:meta # restore file echo 'restore bootstrap/app.php' mv bootstrap/app.php.bak bootstrap/app.php echo 'restore composer dep' composer remove --dev --no-update --no-progress barryvdh/laravel-ide-helper mv composer.json.bak composer.json mv composer.lock.bak composer.lock&#125;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>shell</tag>
        <tag>laravel/lumen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于装修的感悟]]></title>
    <url>%2F2018%2F01%2F03%2F%E5%85%B3%E4%BA%8E%E8%A3%85%E4%BF%AE%E7%9A%84%E6%84%9F%E6%82%9F%2F</url>
    <content type="text"><![CDATA[序言2017年结束了，其实没有什么好review的，设定的计划基本都没完成，甚至忘记了设定了哪些计划。。。不过最后悔的事情还是想记录一下，以此为鉴，望不再犯。整个2017年最后悔的事情当属新房装修了。装修其实从2016年就开始了，耗时整整一年多！漫长的工期结束后，房子却任然漏洞百出。 抛开施工队的种种不专业，出现这种令人不满意的结果其实也和我自身有很大关系。下面来总结下失败的地方：硬装部分硬装可谓是整个家风格样式的基础，十分重要，坑也特别多，工人素质也参差不齐，整体很难把控。一旦完工之后，也很难调整和更换。 所以有必要记录下在硬装部分踩到的坑。装修之前做好充分的准备，多了解，多学习，如果没有时间，就不要去计划。要仔细面试下设计师。不要选择全包，瓷砖，门什么的还是要自己去选牌子货，然后让厂家的工人来施工。花钱请第三方监理。打拆如果打掉了飘窗，一定要想办法避免雨飘进来把墙壁打湿的问题。如果对开发商配的入户门不满意，这时就直接换掉。水电改造如果开发商预置的弱电箱不是很好，这时就直接要求换掉。弱电箱的位置不要和鞋柜位置重叠，也就是说不要把弱电箱藏到鞋柜里面。网线要求质量和品牌，自己买也行。每个房间都要有网线，客厅一定要留至少两个网线口，一进一出。要统一PVC盒子，不要同时使用开发商预置的和水电改造新装上的。PVC盒子的深浅高矮方向要保持一致。用来穿线的PVC管子，尽量保持管内干净，不要让水泥石子落入管内。和装修公司约定好要有电路布线图。如果没有，一定要拍照记录。如果要安装马桶，提前想好安放方向，量好孔距，并且在旁边留一个插座。找平墙体，地面的找平都很重要，务必做好！贴砖要求砖工贴的时候，控制缝隙间距，保持缝隙间距一致，方便后期做美缝。如果有生活阳台，需要在阳台的墙壁上贴砖。地漏提前买好，叮嘱工人不要把水泥弄到地漏的螺纹上。叮嘱工人不要把水泥弄到其他地方，比如说地漏的螺纹，花洒水阀等。提前和工人沟通好阴角阳角的处理方式。吊顶要用铝扣板，干区和湿区都要。总结的这些，希望可以为下一次装修积累一些经验，避免再犯。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Golang reflect 实践]]></title>
    <url>%2F2017%2F12%2F27%2FGolang-reflect-%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[由于最近在用 golang 造一个 query builder + orm 轮子，过程中很多地方涉及到 reflect 包的使用，故写此文章以记录开发中的点滴。建议先去看下 golang 的官方 blog laws-of-reflection 以及 package文档场景示例将 interface{} 转为 []interface{}有时候会遇到这样的情况，我们定义了一个函数，函数会接收一个 interface{} 类型的参数，并且需要在函数体内将这个参数转为一个 slice 即 []interface{}：123456789package mainfunc interfaceSliced(val interface&#123;&#125;) &#123; // TODO: convert `val` into `[]interface&#123;&#125;`&#125;func main() &#123; interfaceSliced([]int&#123;1, 2, 3&#125;) // 调用&#125;这时我们会需要用到 reflect 这个包：123456789101112131415161718192021package mainimport ( "reflect" "fmt")func interfaceSliced(val interface&#123;&#125;) []interface&#123;&#125; &#123; refObj := reflect.ValueOf(val) // 这里会得到一个reflect.Value对象 l := refObj.Len() v := make([]interface&#123;&#125;, l) for i := 0; i &lt; l; i++ &#123; v[i] = refObj.Index(i).Interface() &#125; return v&#125;func main() &#123; s := interfaceSliced([]int&#123;1, 2, 3&#125;) fmt.Printf(`%T %v`, s, s)&#125;当然，最好再加一些类型判断:12345678910111213141516171819202122232425package mainimport ( "reflect" "errors" "fmt")func interfaceSliced(val interface&#123;&#125;) ([]interface&#123;&#125;, error) &#123; refObj := reflect.ValueOf(val) // 这里会得到一个reflect.Value对象 if refObj.Kind() != reflect.Slice &#123; return nil, errors.New("val should be a slice") &#125; l := refObj.Len() v := make([]interface&#123;&#125;, l) for i := 0; i &lt; l; i++ &#123; v[i] = refObj.Index(i).Interface() &#125; return v, nil&#125;func main() &#123; s, err := interfaceSliced([]int&#123;1, 2, 3&#125;) fmt.Printf(`%T %v | %v`, s, s, err)&#125;判断 struct 中是否拥有某方法，如果有，则调用并获取其返回值这个需求的出现是由于想要实现Model的一些特性，比如我们定义了一个名叫 User 的 struct 来作为 Model ，正常来说该 Model 对应的表名称为 users 。 但是如果实际情况中，我们的表名称并不一定是完全按照 CamelCaseSingular to snake_case_plural 来映射了。 这时，一般的做法是在 Model 中定义一个方法或者属性来显示申明对应的表名称：12345678910package maintype User struct &#123; ID int Name string&#125;func (User) TableName() string &#123; return "employees"&#125;上述代码中，我们定义了一个 Model 并且约定用 TableName() 方法来显示地申明了该 Model 对应的表名称。 我们在解析 Model 的时候就需要去判断是否存在 TableName() 方法，如果存在，则调用，从而获取表名称；如果不存在，则按照 CamelCaseSingular to snake_case_plural 的原则来得到表名称。 想要实现这个功能，则需要用到 reflect 包和其中的 MethodByName()方法文档：123456789101112type Type interface &#123; // MethodByName returns the method with that name in the type's // method set and a boolean indicating if the method was found. // // For a non-interface type T or *T, the returned Method's Type and Func // fields describe a function whose first argument is the receiver. // // For an interface type, the returned Method's Type field gives the // method signature, without a receiver, and the Func field is nil. MethodByName(string) (Method, bool) // ...代码实现：12345678910111213141516171819package mainimport ( "reflect")func findOutTableName(struc interface&#123;&#125;) string &#123; v := reflect.ValueOf(struc) typ := v.Type() var tbName string if _, ok := typ.MethodByName("TableName"); ok &#123; // 如果存在，则调用 tbName = v.MethodByName("TableName").Call(nil)[0].String() &#125; if tbName == "" &#123; // TODO: CamelCaseSingular to snake_case_plural &#125; return tbName&#125;两块代码合在一起：1234567891011121314151617181920212223242526272829303132333435package mainimport ( "fmt" "reflect")// User stands for User Modeltype User struct &#123; ID int Name string&#125;// TableName specifies the table name of User Modelfunc (User) TableName() string &#123; return "employees"&#125;func findOutTableName(struc interface&#123;&#125;) string &#123; v := reflect.ValueOf(struc) typ := v.Type() var tbName string if _, ok := typ.MethodByName("TableName"); ok &#123; tbName = v.MethodByName("TableName").Call(nil)[0].String() &#125; if tbName == "" &#123; // TODO: CamelCaseSinglar to snake_case_plural 这里就不做演示了 &#125; return tbName&#125;func main() &#123; user := User&#123;&#125; fmt.Println(findOutTableName(user)) // employees&#125;To be continued...]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识gRPC]]></title>
    <url>%2F2017%2F12%2F19%2F%E5%88%9D%E8%AF%86gRPC%2F</url>
    <content type="text"><![CDATA[写这篇文章用于记录首次接触gRPC的感受。官网：grpc.io先上一张核心概念的流程图：看了看官方文档，也有了初步的一个认识。个人觉得这个框架中最厉害的是 protobuf 的目标语言 generator ，整个框架的核心也是围绕着这个生成器展开的。核心思路使用 .proto 文件编写方法、参数、返回(类似路由规则)，再通过 generator 生成各种语言的文件 比如 Golang PHP Javascript 等。 在服务端和客户端引入生成的语言文件即可进行业务代码开发，由此达到了跨语言的调用。举个例子虽然官方等文档已经写的比较清晰了，但是还是想在这里记录一下自己跟着官网打教程体验。这里暂且只记录 Golang 的教程在 .proto 文件中定义方法、参数、返回先来一个最简单的：1234567891011121314151617// file: $GOPATH/src/proto/user.protosyntax = &quot;proto3&quot;;package proto; // 包名service User &#123; rpc all (Request) returns (Response);&#125;message Request &#123; string json = 1;&#125;message Response &#123; string json = 1;&#125;这个简单的 .proto 文件定义了 一个路由组 user 和 这个路由组里的一个 all 方法， 这个 all 方法需要接收一个 Request 对象作为参数，Request 对象中有一个 json 属性，类型是 string， 同时，这个 all 方法会返回一个 Response 对象，Response 对象中有一个 json 属性，类型是 string。下一步，我们需要将这个 .proto 文件转换为我们的开发语言，也就是 Golang。转换等方式也很简单，一个命令就可以搞定。 但是在使用这个命令前，我们需要安装一些依赖，这些依赖会根据目标语言的不同而不同，具体内容可以参考文档。安装 Protocol Buffers v3Install the protoc compiler that is used to generate gRPC service code. The simplest way to do this is to download pre-compiled binaries for your platform(protoc--.zip) from here: https://github.com/google/protobuf/releases Unzip this file. Update the environment variable PATH to include the path to the protoc binary file.然后安装 the protoc plugin for Go1go get -u -v github.com/golang/protobuf/protoc-gen-go检查下环境变量1echo $path # 应该包含 /path/to/protoc 和 $GOPATH执行命令，生成 golang 代码12cd $GOPATH/srcprotoc -I proto proto/*.proto --go_out=plugins=grpc:proto完成后你会得到一个 user.pb.go 文件，其 package 是 proto 正如在 user.proto 文件中定义的一样当然针对不同的目标语言，命令的参数是不一样的，具体可以参考官方文档。有了 user.pb.go 文件，引用之后，编写 server 和 client 就很轻松了。thanks to code hint. 当然，首先需要安装 gRPC 框架1go get -u -v google.golang.org/grpc编写server直接看代码123456789101112131415161718192021222324252627282930313233343536// file: $GOPATH/src/server/main.gopackage mainimport ( "log" "net" "proto" "google.golang.org/grpc" "golang.org/x/net/context")var address string = ":6666"type server struct &#123;&#125;// 这里等方法名称必须是大写开头，应该是由于golang的语言特性func (s *server) All(ctx context.Context, req *proto.Request) (*proto.Response, error) &#123; // handle req... return &amp;proto.Response&#123;Json: "user list"&#125;, nil&#125;func main() &#123; lis, err := net.Listen("tcp", address) if err != nil &#123; log.Fatalf("failed to listen: %v", err) &#125; // 注册服务 grpcServer := grpc.NewServer() proto.RegisterUserServer(grpcServer, &amp;server&#123;&#125;) // 监听 if err := grpcServer.Serve(lis); err != nil &#123; log.Fatalf("failed to serve: %v", err) &#125;&#125;执行 server12cd $GOPATH/srcgo run server/main.go编写client直接看代码12345678910111213141516171819202122232425262728293031// file: $GOPATH/src/client/main.gopackage mainimport ( "golang.org/x/net/context" "google.golang.org/grpc" "log" "proto")var address string = "localhost:6666" // 和server保持一致func main() &#123; var response *proto.Response var err error // 拨号建立连接 conn, err := grpc.Dial(address, grpc.WithInsecure()) if err != nil &#123; log.Fatalf("did not connect: %v", err) &#125; defer conn.Close() // rpc调用 users := proto.NewUserClient(conn) response, err = users.All(context.Background(), &amp;proto.Request&#123;Json: "string param"&#125;) if err != nil &#123; log.Fatalf("could not call user.All: %v", err) &#125; log.Print(response.Json) // 输出响应&#125;执行 client12cd $GOPATH/srcgo run client/main.go输出12017/12/19 11:52:44 user list总结第一个教程打完了。感觉最主要的功劳还是 generator 😆更新生成目标语言的命令：(目前只在Mac上测试过)1234567891011121314cd protos # 假设这里放的是 .proto 文件# golangmkdir go# 需要安装插件 go get -u -v github.com/golang/protobuf/protoc-gen-goprotoc --go_out=./go *.proto # 有木有很简单。。# nodemkdir node# 需要安装插件 npm install -g grpc-toolsprotoc --js_out=import_style=commonjs,binary:./node --grpc_out=./node --plugin=protoc-gen-grpc=`which grpc_tools_node_protoc_plugin` *.proto# 会生成两种文件 *_pb.js 和 *_grpc_pb.js# 前者用于访问 request 和 response# 后者用于创建 server 和 client 以及方法调用]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>golang</tag>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Merry Christmas Soon]]></title>
    <url>%2F2017%2F12%2F16%2FMerry-Christmas-Soon%2F</url>
    <content type="text"><![CDATA[圣诞节马上到了，祝亲爱的Mix圣诞节快乐！一直很心疼你周六还要上班。昨天你兴高采烈地告诉我，今天你的好闺蜜约你去玩，你很开心。 看到这样开心的你，我感到幸福无比。 希望今后的日子里，我们都能够开开心心，有困难我们一起面对，天塌下来，有我顶着。 路遥远，我们一起走。 爱你。 ❤️]]></content>
      <categories>
        <category>感情</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Golang中的时间符号规律]]></title>
    <url>%2F2017%2F11%2F11%2FGolang%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4%E7%AC%A6%E5%8F%B7%E8%A7%84%E5%BE%8B%2F</url>
    <content type="text"><![CDATA[Origin of “Mon Jan 2 15:04:05 MST 2006” in golangIt is just the numbers 1 2 3 4 5 6 71: month (January, Jan, 01, etc)2: day3: hour (15 is 3pm on a 24 hour clock)4: minute5: second6: year (2006)7: timezone (GMT-7 is MST)😆 😆 😆]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下使用adb将本地文件拷贝到安卓手机]]></title>
    <url>%2F2017%2F11%2F11%2FMac%E4%B8%8B%E4%BD%BF%E7%94%A8adb%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%96%87%E4%BB%B6%E6%8B%B7%E8%B4%9D%E5%88%B0%E5%AE%89%E5%8D%93%E6%89%8B%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[Mac下使用 adb 将本地文件拷贝到安卓手机一直想在Mac上找个好用的图形界面的安卓手机助手类的工具，但是寻寻觅觅，还是没有找到，只好用adb来实现了。安装adb使用homebrew快速安装1$ brew cask install android-platform-tools验证是否已安装1$ which adb使用adb push文件到手机上确保adb识别到了你的手机首先需要在手机上打开USB调试然后可以在终端执行1$ adb devices来判断adb是否识别到了你的手机拷贝本地文件到手机上adb 提供了 push 命令，即可复制本地文件到手机上1$ adb push file.on.mac.zip /sdcard/path/Tips关于手机上的路径，可以使用 adb shell 来进入手机的目录结构，然后可以尝试下 pwd]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install Shadowsocks server on ubuntu]]></title>
    <url>%2F2017%2F10%2F12%2FInstall-Shadowsocks-server-on-ubuntu%2F</url>
    <content type="text"><![CDATA[这里有两种方式:Docker 方式推荐一个docker镜像 mritd/shadowsocks下面是docker-compose.yml12345678910111213141516version: '3'services: ssclient: image: mritd/shadowsocks:latest container_name: ssclient ports: - 1080:1080 # # 用作client # # command: -m "ss-local" -s "-s 12.34.56.78 -p 8388 -m rc4-md5 -k password -b 0.0.0.0 -l 1080 --fast-open" # # 用作server # command: -m "ss-server" -s "-s 0.0.0.0 -p 8388 -m aes-256-cfb -k password --fast-open"传统安装方式Installation1234$ sudo apt-get update$ sudo apt-get upgrade -y$ sudo apt-get install python-gevent python-pip python-m2crypto python-wheel python-setuptools$ sudo pip install shadowsocksConfig and Start the serviceconfig file ss.json:12345678910&#123; "server": "0.0.0.0", "server_port": 8388, "local_address": "127.0.0.1", "local_port": 1080, "password": "my_password", "timeout": 300, "method": "rc4-md5", "fast_open": true&#125;start:1$ sudo ssserver -c ss.json -d start # run as daemon]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>shadowsocks</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梅林单线复用Internet+IPTV]]></title>
    <url>%2F2017%2F10%2F09%2F%E6%A2%85%E6%9E%97%E5%8D%95%E7%BA%BF%E5%A4%8D%E7%94%A8internet%2BIPTV%2F</url>
    <content type="text"><![CDATA[此方法已无效，无法拿到 backupsettings.conf 了，电信后台修复了这个BUG由于装修时网络布线问题，需要把电信光猫的IPTV业务在路由器中和Internet业务分开，达到单线复用设备路由器: 华硕ac68u 刷了 梅林7.5电信光猫版本: TEWA-500E开始电信光猫之所以可以做到将Internet和IPTV的流量分开，是由于设置了VLAN，所以需要把光猫的VLAN设置让路由器来接管，在路由器上配置Internet和IPTV的VLAN。找到原有的VLAN配置首先需要拿到光猫的超级管理员的账号密码。TEWA-500E的获取方式比较简单登录登录之后，在地址栏中输入 192.168.1.1/backupsettings.conf 会下载到光猫的配置文件打开配置文件，搜索关键字 telecom (忽略大小写) 可以找到密码的配置，在&lt;Password&gt;中间123&lt;X_CT-COM_TeleComAccount&gt; &lt;Password&gt;密码&lt;/Password&gt;&lt;/X_CT-COM_TeleComAccount&gt;重新登录光猫 账号: telecomadmin，密码: 找到的密码以超级管理员账号登录后，可以看到VLAN的配置 需要记下上面两个的VLAN IDInternet的连接模式可以设为桥接（非必须），设为桥接后，则需要在路由器完成拨号。从上图中可以看到，IPTV的VLAN ID是43，Internet的VLAN ID是1372。然后在VLAN绑定中添加一组在路由器中(梅林固件)，手动配置VLAN配置如下连线将光猫的lan1口接入路由器的wan（如果Internet业务为桥接模式的话，需要在路由器上完成PPPoE拨号），然后将路由器的lan4口接入IPTV盒子。大功告成！]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>router</tag>
        <tag>merlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac版搜狗输入法自动英文添加spotlight.app]]></title>
    <url>%2F2017%2F10%2F09%2FMac%E7%89%88%E6%90%9C%E7%8B%97%E8%BE%93%E5%85%A5%E6%B3%95%E8%87%AA%E5%8A%A8%E8%8B%B1%E6%96%87%E6%B7%BB%E5%8A%A0spotlight-app%2F</url>
    <content type="text"><![CDATA[主要的问题在于不知道 spotlight.app 的位置，后来找到了，一些系统级的APP都在 /System/Library/CoreServices/ 路径下，找到后添加即可。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
</search>
